{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HouseBrain Data Factory 2.0: The Architect's Assembly Line (Parallel Mode)\n",
        "\n",
        "This notebook is the control center for generating a high-quality, architecturally-sound dataset for training the HouseBrain LLM. It is designed for **large-scale, parallel data generation.**\n",
        "\n",
        "**Our Strategy:**\n",
        "1.  **Generate a Master Prompt File (Once)**: Run Cell 4 a single time to generate a large (e.g., 30,000) list of prompts and save it to your Google Drive.\n",
        "2.  **Run Multiple Notebooks in Parallel**: You can open this same notebook using different Google accounts.\n",
        "3.  **Process Random Batches**: Each notebook instance will read from the master prompt list, select a random, unique batch of prompts to process, and save the results to a central dataset folder on your Drive.\n",
        "4.  **Avoid Duplicate Work**: The script checks if a plan for a given prompt already exists, allowing multiple instances to contribute to the same dataset without collisions.\n",
        "\n",
        "## Instructions\n",
        "1.  **Set Your GitHub PAT**: In Cell 1, you will be prompted to enter a GitHub Personal Access Token to clone the repository.\n",
        "2.  **(First Time Only) Run Cell 4**: Run Cell 4 to create your master `platinum_prompts.txt` file in Google Drive. You only need to do this once.\n",
        "3.  **Run the Factory (Cell 3)**: Run cells 1, 2, and 3. You can configure the number of plans you want the current notebook instance to generate in Cell 3.\n",
        "4.  **Repeat**: Open this notebook with other accounts, mount the same Google Drive, and run Cell 3 again to generate more data in parallel.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 1. Setup Environment\n",
        "# @markdown Mount Google Drive and clone the repository using a secure token.\n",
        "from google.colab import drive\n",
        "import os\n",
        "import getpass\n",
        "import subprocess\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"‚úÖ Google Drive mounted.\")\n",
        "\n",
        "# --- GitHub Setup ---\n",
        "#@markdown Enter your GitHub Personal Access Token (PAT) with repo access.\n",
        "GITHUB_TOKEN = getpass.getpass('Enter your GitHub PAT: ')\n",
        "REPO_URL = f\"https://{GITHUB_TOKEN}@github.com/Vinay-O/HouseBrainLLM.git\"\n",
        "REPO_DIR = \"/content/HouseBrainLLM\"\n",
        "\n",
        "# Clone the repository\n",
        "if os.path.exists(REPO_DIR):\n",
        "    print(\"Repository already exists. Pulling latest changes...\")\n",
        "    # Use subprocess.run for better error handling\n",
        "    subprocess.run(f\"cd {REPO_DIR} && git pull\", shell=True, check=True)\n",
        "else:\n",
        "    print(\"Cloning repository...\")\n",
        "    subprocess.run(f\"git clone {REPO_URL} {REPO_DIR}\", shell=True, check=True)\n",
        "\n",
        "print(\"‚úÖ Repository is ready.\")\n",
        "\n",
        "# --- Install Dependencies ---\n",
        "#@markdown Install necessary Python packages from the new requirements file.\n",
        "requirements_path = os.path.join(REPO_DIR, \"requirements.txt\")\n",
        "if os.path.exists(requirements_path):\n",
        "    print(\"Installing dependencies from requirements.txt...\")\n",
        "    !pip install -q -r {requirements_path}\n",
        "    print(\"‚úÖ Dependencies installed.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è requirements.txt not found. Installing default packages.\")\n",
        "    !pip install -q pydantic\n",
        "\n",
        "print(\"‚úÖ Environment setup complete.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 2. Configure and Start Ollama Server\n",
        "# @markdown This cell will download and start the Ollama server, then pull the specified model.\n",
        "# @markdown **NOTE:** A powerful model like `deepseek-r1:32b` is now recommended for higher quality results. It will be slower but more reliable.\n",
        "\n",
        "MODEL_NAME = \"deepseek-r1:32b\" # @param [\"deepseek-r1:32b\", \"llama3:70b-instruct\", \"qwen2:72b-instruct\", \"mixtral:instruct\"]\n",
        "\n",
        "# Download and start Ollama\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "import threading\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "def run_ollama():\n",
        "    try:\n",
        "        subprocess.run(\"ollama serve\", shell=True, check=True, capture_output=True, text=True)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Ollama server failed: {e.stderr}\")\n",
        "\n",
        "print(\"üöÄ Starting Ollama server in the background...\")\n",
        "ollama_thread = threading.Thread(target=run_ollama)\n",
        "ollama_thread.daemon = True\n",
        "ollama_thread.start()\n",
        "\n",
        "# Wait for the server to be ready\n",
        "print(\"‚è≥ Waiting for Ollama server to initialize...\")\n",
        "time.sleep(15) # Increased wait time for stability\n",
        "\n",
        "# Pull the model\n",
        "print(f\"üì¶ Pulling model: {MODEL_NAME}. This may take a while...\")\n",
        "try:\n",
        "    process = subprocess.run(\n",
        "        f\"ollama pull {MODEL_NAME}\",\n",
        "        shell=True, check=True, capture_output=True, text=True, timeout=900\n",
        "    )\n",
        "    print(f\"‚úÖ Model {MODEL_NAME} is ready.\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Error pulling model: {e.stderr}\")\n",
        "    print(\"This might happen if the model name is incorrect or the Ollama server is not ready.\")\n",
        "except subprocess.TimeoutExpired:\n",
        "    print(\"Timed out while pulling the model. The model might be very large or the connection slow.\")\n",
        "\n",
        "\n",
        "# Verify Ollama is running\n",
        "!ollama list\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 3. Run the Data Factory (V3: Assembly Line)\n",
        "# @markdown This cell implements the **\"Assembly Line\"** strategy (Plan C).\n",
        "# @markdown It breaks down the complex task of generating a house plan into a series of smaller, more reliable steps, and then assembles the final product with code. This is a more robust and professional approach to AI-driven data generation.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import textwrap\n",
        "import logging\n",
        "from pathlib import Path\n",
        "import urllib.request\n",
        "import urllib.error\n",
        "from inspect import getsource\n",
        "from pydantic import BaseModel, ValidationError\n",
        "import random\n",
        "import hashlib\n",
        "import time\n",
        "import re\n",
        "\n",
        "# --- Configuration ---\n",
        "DRIVE_PROMPT_FILE = \"/content/drive/MyDrive/housebrain_prompts/platinum_prompts.txt\" #@param {type:\"string\"}\n",
        "DRIVE_OUTPUT_DIR = \"/content/drive/MyDrive/housebrain_platinum_dataset\" #@param {type:\"string\"}\n",
        "NUM_PLANS_TO_GENERATE = 100 #@param {type:\"integer\"}\n",
        "MODEL_NAME = \"deepseek-r1:32b\" # @param [\"deepseek-r1:32b\", \"llama3:70b-instruct\", \"qwen2:72b-instruct\", \"mixtral:instruct\"]\n",
        "# --- End Configuration ---\n",
        "\n",
        "\n",
        "# --- Setup ---\n",
        "REPO_DIR = \"/content/HouseBrainLLM\"\n",
        "if REPO_DIR not in sys.path: sys.path.insert(0, REPO_DIR)\n",
        "os.chdir(REPO_DIR)\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "try:\n",
        "    from src.housebrain.schema import HouseOutput, RoomType\n",
        "    print(\"‚úÖ Successfully imported HouseBrain schema.\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Failed to import HouseBrain schema: {e}\")\n",
        "    raise e\n",
        "\n",
        "# --- Prompts for Assembly Line ---\n",
        "VALID_ROOM_TYPES = [e.value for e in RoomType]\n",
        "VALID_WINDOW_TYPES = [\"fixed\", \"casement\", \"sliding\", \"bay\"]\n",
        "VALID_DOOR_TYPES = [\"interior\", \"exterior\", \"sliding\", \"pocket\"]\n",
        "\n",
        "STAGE_1_LAYOUT_PROMPT = \"\"\"You are an expert AI architect. Your task is to generate ONLY the high-level geometric layout for a house based on a user's prompt.\n",
        "\n",
        "**CRITICAL INSTRUCTIONS:**\n",
        "1.  Focus ONLY on `levels` and `rooms`.\n",
        "2.  Rooms MUST have an `id`, `type`, and non-overlapping `bounds`. **BOUNDS MUST NOT OVERLAP.**\n",
        "3.  The `type` for each room MUST be one of the following valid options: `{valid_room_types}`. Do NOT invent new types or use shorthands.\n",
        "4.  **Size Constraint**: Rooms must have realistic dimensions. For example, an `entrance` must be at least 40 sqft, a `bathroom` at least 40 sqft, and a `bedroom` at least 120 sqft.\n",
        "5.  DO NOT include `doors` or `windows`.\n",
        "6.  Your output MUST be a single, valid JSON object with a root \"levels\" key.\n",
        "---\n",
        "**User Prompt:**\n",
        "{user_prompt}\n",
        "---\n",
        "Now, generate ONLY the JSON for the house layout.\"\"\"\n",
        "\n",
        "STAGE_2_DOORS_PROMPT = \"\"\"You are an AI architect. Given the JSON layout of a house, your task is to generate ONLY a JSON list of Door objects to connect the rooms logically.\n",
        "\n",
        "**CRITICAL INSTRUCTIONS:**\n",
        "1.  Your output MUST be a single, valid JSON list `[...]`.\n",
        "2.  Each object in the list must be a valid Door, with `position`, `width`, `type`, `room1`, and `room2`.\n",
        "3.  The `type` MUST be one of: `{valid_door_types}`.\n",
        "4.  `room1` and `room2` MUST be valid room IDs from the provided layout. For an exterior door, you may use an invented ID like \"exterior_0\" for `room2`.\n",
        "\n",
        "**Golden Example of a perfect output:**\n",
        "```json\n",
        "[\n",
        "  {{\n",
        "    \"position\": {{ \"x\": 20, \"y\": 25 }},\n",
        "    \"width\": 3.0,\n",
        "    \"type\": \"interior\",\n",
        "    \"room1\": \"living_room_0\",\n",
        "    \"room2\": \"dining_room_0\"\n",
        "  }}\n",
        "]\n",
        "```\n",
        "---\n",
        "**House Layout:**\n",
        "```json\n",
        "{house_layout}\n",
        "```\n",
        "---\n",
        "Now, generate ONLY the JSON list of Door objects.\"\"\"\n",
        "\n",
        "STAGE_3_WINDOWS_PROMPT = \"\"\"You are an AI architect. Given the JSON layout of a house, your task is to generate ONLY a JSON list of Window objects.\n",
        "\n",
        "**CRITICAL INSTRUCTIONS:**\n",
        "1.  Your output MUST be a single, valid JSON list `[...]`.\n",
        "2.  Each object in the list must be a valid Window, with `position`, `width`, `height`, `type`, and `room_id`.\n",
        "3.  The `type` MUST be one of: `{valid_window_types}`.\n",
        "4.  The `room_id` MUST be a valid room ID from the provided layout.\n",
        "5.  Place windows on walls that would logically be exterior walls.\n",
        "\n",
        "**Golden Example of a perfect output:**\n",
        "```json\n",
        "[\n",
        "  {{\n",
        "    \"position\": {{ \"x\": 10, \"y\": 17.5 }},\n",
        "    \"width\": 8.0,\n",
        "    \"height\": 5.0,\n",
        "    \"type\": \"sliding\",\n",
        "    \"room_id\": \"living_room_0\"\n",
        "  }}\n",
        "]\n",
        "```\n",
        "---\n",
        "**House Layout:**\n",
        "```json\n",
        "{house_layout}\n",
        "```\n",
        "---\n",
        "Now, generate ONLY the JSON list of Window objects.\"\"\"\n",
        "\n",
        "JSON_REPAIR_PROMPT = \"\"\"The following text is not a valid JSON object. Please fix any syntax errors (like missing commas, brackets, or quotes) and return ONLY the corrected, valid JSON object. Do not add any commentary.\n",
        "\n",
        "**Broken Text:**\n",
        "{broken_json}\n",
        "\"\"\"\n",
        "\n",
        "# --- Core Functions ---\n",
        "def call_ollama_colab(model_name: str, prompt: str, max_retries=3):\n",
        "    url = \"http://localhost:11434/api/generate\"\n",
        "    data = {\"model\": model_name, \"prompt\": prompt, \"stream\": False, \"format\": \"json\"}\n",
        "    encoded_data = json.dumps(data).encode('utf-8')\n",
        "    req = urllib.request.Request(url, data=encoded_data, headers={'Content-Type': 'application/json'})\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            with urllib.request.urlopen(req, timeout=900) as response:\n",
        "                if response.status == 200:\n",
        "                    return json.loads(response.read().decode('utf-8')).get(\"response\", \"\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Attempt {attempt + 1}/{max_retries} failed. Error calling Ollama: {e}\")\n",
        "            if attempt < max_retries - 1: time.sleep(5)\n",
        "            else: logger.error(\"Max retries reached. Failing.\")\n",
        "    return None\n",
        "\n",
        "def repair_json(raw_json_str: str, model_name: str, target_type: type):\n",
        "    \"\"\"More robustly finds, parses, and repairs a JSON string.\"\"\"\n",
        "    if not raw_json_str: return None\n",
        "    \n",
        "    # 1. Aggressive Regex Extraction\n",
        "    clean_str = None\n",
        "    if target_type == list:\n",
        "        match = re.search(r'\\[.*\\]', raw_json_str, re.DOTALL)\n",
        "        if match: clean_str = match.group(0)\n",
        "    else: # dict\n",
        "        match = re.search(r'\\{.*\\}', raw_json_str, re.DOTALL)\n",
        "        if match: clean_str = match.group(0)\n",
        "\n",
        "    if clean_str:\n",
        "        try:\n",
        "            data = json.loads(clean_str)\n",
        "            if isinstance(data, target_type): return data\n",
        "        except json.JSONDecodeError:\n",
        "            pass # Fall through to LLM repair\n",
        "\n",
        "    # 2. Fallback to LLM Repair\n",
        "    print(f\"Initial parse for type {target_type.__name__} failed. Attempting LLM repair...\")\n",
        "    repair_prompt = JSON_REPAIR_PROMPT.format(broken_json=raw_json_str)\n",
        "    repaired_str = call_ollama_colab(model_name, repair_prompt)\n",
        "    if not repaired_str:\n",
        "        print(\"‚ùå JSON repair failed: No response from model.\")\n",
        "        return None\n",
        "    try:\n",
        "        data = json.loads(repaired_str)\n",
        "        if isinstance(data, target_type):\n",
        "            print(f\"‚úÖ JSON successfully repaired to type {target_type.__name__}.\")\n",
        "            return data\n",
        "        # Handle cases where model wraps list in a dict\n",
        "        if target_type == list and isinstance(data, dict) and len(data.keys()) == 1:\n",
        "            for key, value in data.items():\n",
        "                if isinstance(value, list):\n",
        "                    print(f\"‚úÖ Repaired JSON by extracting list from key '{key}'.\")\n",
        "                    return value\n",
        "        print(f\"‚ùå Repaired JSON is not of target type {target_type.__name__}.\")\n",
        "        return None\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"‚ùå JSON parse failed even after LLM repair.\")\n",
        "        return None\n",
        "\n",
        "def assemble_plan(layout_dict, doors_list, windows_list):\n",
        "    \"\"\"A completely bulletproof assembly function that can handle any malformed data.\"\"\"\n",
        "    # Safety wrapper for dict access to handle any possible type error\n",
        "    def safe_get(d, key, default=None):\n",
        "        try:\n",
        "            if not isinstance(d, dict):\n",
        "                return default\n",
        "            return d.get(key, default)\n",
        "        except:\n",
        "            return default\n",
        "    \n",
        "    # Initialize an empty result with a safe structure\n",
        "    result = {\"levels\": []}\n",
        "    \n",
        "    # Safely extract and verify the levels\n",
        "    try:\n",
        "        if not isinstance(layout_dict, dict):\n",
        "            print(\"‚ö†Ô∏è Assembly Error: Layout is not a dictionary. Creating empty layout.\")\n",
        "            return result\n",
        "            \n",
        "        levels = safe_get(layout_dict, \"levels\", [])\n",
        "        if not isinstance(levels, list):\n",
        "            print(\"‚ö†Ô∏è Assembly Error: 'levels' key is not a list. Creating empty layout.\")\n",
        "            return result\n",
        "            \n",
        "        result[\"levels\"] = levels\n",
        "        \n",
        "        # Create a safe room lookup dictionary\n",
        "        rooms_by_id = {}\n",
        "        \n",
        "        # Process each level and room with complete safety\n",
        "        for level_idx, level in enumerate(levels):\n",
        "            try:\n",
        "                if not isinstance(level, dict):\n",
        "                    print(f\"‚ö†Ô∏è Assembly Warning: Skipping non-dict level at index {level_idx}.\")\n",
        "                    continue\n",
        "                    \n",
        "                # Initialize an empty rooms list if needed\n",
        "                if \"rooms\" not in level or not isinstance(level[\"rooms\"], list):\n",
        "                    level[\"rooms\"] = []\n",
        "                    continue\n",
        "                    \n",
        "                # Process each room\n",
        "                for room_idx, room in enumerate(level[\"rooms\"]):\n",
        "                    try:\n",
        "                        if not isinstance(room, dict):\n",
        "                            print(f\"‚ö†Ô∏è Assembly Warning: Skipping non-dict room at index {room_idx}.\")\n",
        "                            continue\n",
        "                            \n",
        "                        room_id = safe_get(room, \"id\")\n",
        "                        if not isinstance(room_id, str):\n",
        "                            print(f\"‚ö†Ô∏è Assembly Warning: Room has invalid ID: {room_id}\")\n",
        "                            continue\n",
        "                            \n",
        "                        # Initialize empty collections for doors and windows\n",
        "                        if \"doors\" not in room or not isinstance(room[\"doors\"], list):\n",
        "                            room[\"doors\"] = []\n",
        "                        if \"windows\" not in room or not isinstance(room[\"windows\"], list):\n",
        "                            room[\"windows\"] = []\n",
        "                            \n",
        "                        # Add to lookup\n",
        "                        rooms_by_id[room_id] = room\n",
        "                    except Exception as e:\n",
        "                        print(f\"‚ö†Ô∏è Assembly Warning: Error processing room: {str(e)}\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Assembly Warning: Error processing level: {str(e)}\")\n",
        "    \n",
        "        # Process windows safely\n",
        "        if isinstance(windows_list, list):\n",
        "            for window_idx, window in enumerate(windows_list):\n",
        "                try:\n",
        "                    if not isinstance(window, dict):\n",
        "                        print(f\"‚ö†Ô∏è Assembly Warning: Discarding non-dict window at index {window_idx}: {window}\")\n",
        "                        continue\n",
        "                        \n",
        "                    room_id = safe_get(window, \"room_id\")\n",
        "                    if not isinstance(room_id, str) or room_id not in rooms_by_id:\n",
        "                        print(f\"‚ö†Ô∏è Assembly Warning: Window has invalid room_id: {room_id}\")\n",
        "                        continue\n",
        "                        \n",
        "                    # Verify window has required fields\n",
        "                    required_fields = [\"position\", \"width\", \"height\", \"type\"]\n",
        "                    for field in required_fields:\n",
        "                        if field not in window:\n",
        "                            print(f\"‚ö†Ô∏è Assembly Warning: Window missing required field: {field}\")\n",
        "                            break\n",
        "                    else:\n",
        "                        # All checks passed, safe to add\n",
        "                        rooms_by_id[room_id][\"windows\"].append(window)\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è Assembly Warning: Error processing window: {str(e)}\")\n",
        "    \n",
        "        # Process doors safely\n",
        "        if isinstance(doors_list, list):\n",
        "            for door_idx, door in enumerate(doors_list):\n",
        "                try:\n",
        "                    if not isinstance(door, dict):\n",
        "                        print(f\"‚ö†Ô∏è Assembly Warning: Discarding non-dict door at index {door_idx}: {door}\")\n",
        "                        continue\n",
        "                        \n",
        "                    room1_id = safe_get(door, \"room1\")\n",
        "                    if not isinstance(room1_id, str) or room1_id not in rooms_by_id:\n",
        "                        print(f\"‚ö†Ô∏è Assembly Warning: Door has invalid room1_id: {room1_id}\")\n",
        "                        continue\n",
        "                        \n",
        "                    # Verify door has required fields\n",
        "                    required_fields = [\"position\", \"width\", \"type\", \"room2\"]\n",
        "                    for field in required_fields:\n",
        "                        if field not in door:\n",
        "                            print(f\"‚ö†Ô∏è Assembly Warning: Door missing required field: {field}\")\n",
        "                            break\n",
        "                    else:\n",
        "                        # All checks passed, safe to add\n",
        "                        rooms_by_id[room1_id][\"doors\"].append(door)\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è Assembly Warning: Error processing door: {str(e)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Assembly Error: Unexpected error during assembly: {str(e)}\")\n",
        "    \n",
        "    return result\n",
        "\n",
        "# --- Execution ---\n",
        "print(\"--- Starting Data Factory Run (V3: Assembly Line) ---\")\n",
        "Path(DRIVE_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "try:\n",
        "    with open(DRIVE_PROMPT_FILE, 'r') as f:\n",
        "        all_prompts = [line.strip() for line in f if line.strip()]\n",
        "    print(f\"‚úÖ Found {len(all_prompts)} total prompts in the master list.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå MASTER PROMPT FILE NOT FOUND at '{DRIVE_PROMPT_FILE}'.\")\n",
        "    all_prompts = []\n",
        "\n",
        "if all_prompts:\n",
        "    random.shuffle(all_prompts)\n",
        "    prompts_to_process = all_prompts[:NUM_PLANS_TO_GENERATE]\n",
        "    print(f\"‚úÖ This run will process a random batch of {len(prompts_to_process)} prompts.\")\n",
        "\n",
        "    for i, prompt_text in enumerate(prompts_to_process):\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(f\"Processing prompt {i+1}/{len(prompts_to_process)}\")\n",
        "        \n",
        "        run_name = f\"plan_{hashlib.sha1(prompt_text.encode()).hexdigest()[:16]}\"\n",
        "        output_file = Path(DRIVE_OUTPUT_DIR) / f\"{run_name}.json\"\n",
        "\n",
        "        if output_file.exists():\n",
        "            print(f\"‚è≠Ô∏è Skipping prompt, output file already exists: {output_file.name}\")\n",
        "            continue\n",
        "        \n",
        "        print(textwrap.shorten(prompt_text, width=100, placeholder=\"...\"))\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        # --- STAGE 1: Generate Layout ---\n",
        "        print(\"Running Stage 1: Layout Generation...\")\n",
        "        stage_1_prompt = STAGE_1_LAYOUT_PROMPT.format(user_prompt=prompt_text, valid_room_types=VALID_ROOM_TYPES)\n",
        "        layout_str = call_ollama_colab(MODEL_NAME, stage_1_prompt)\n",
        "        layout_dict = repair_json(layout_str, MODEL_NAME, dict)\n",
        "        if not layout_dict or not layout_dict.get(\"levels\"):\n",
        "            print(\"‚ùå Stage 1 Failed: Could not produce a valid layout dictionary.\")\n",
        "            with open(str(output_file).replace('.json', '_s1_failed.txt'), 'w') as f: f.write(layout_str or \"\")\n",
        "            continue\n",
        "        \n",
        "        # --- STAGE 2: Generate Doors ---\n",
        "        print(\"Running Stage 2: Door Generation...\")\n",
        "        stage_2_prompt = STAGE_2_DOORS_PROMPT.format(house_layout=json.dumps(layout_dict, indent=2), valid_door_types=VALID_DOOR_TYPES)\n",
        "        doors_str = call_ollama_colab(MODEL_NAME, stage_2_prompt)\n",
        "        doors_list = repair_json(doors_str, MODEL_NAME, list)\n",
        "        if doors_list is None: # An empty list is a valid result\n",
        "            print(\"‚ùå Stage 2 Failed: Could not produce a valid list of doors.\")\n",
        "            with open(str(output_file).replace('.json', '_s2_failed.txt'), 'w') as f: f.write(doors_str or \"\")\n",
        "            continue\n",
        "\n",
        "        # --- STAGE 3: Generate Windows ---\n",
        "        print(\"Running Stage 3: Window Generation...\")\n",
        "        stage_3_prompt = STAGE_3_WINDOWS_PROMPT.format(house_layout=json.dumps(layout_dict, indent=2), valid_window_types=VALID_WINDOW_TYPES)\n",
        "        windows_str = call_ollama_colab(MODEL_NAME, stage_3_prompt)\n",
        "        windows_list = repair_json(windows_str, MODEL_NAME, list)\n",
        "        if windows_list is None: # An empty list is a valid result\n",
        "            print(\"‚ùå Stage 3 Failed: Could not produce a valid list of windows.\")\n",
        "            with open(str(output_file).replace('.json', '_s3_failed.txt'), 'w') as f: f.write(windows_str or \"\")\n",
        "            continue\n",
        "\n",
        "        # --- STAGE 4: Assemble & Validate ---\n",
        "        print(\"Running Stage 4: Assembling and Validating...\")\n",
        "        try:\n",
        "            assembled_plan_dict = assemble_plan(layout_dict, doors_list, windows_list)\n",
        "            \n",
        "            processed_levels = assembled_plan_dict.get(\"levels\", [])\n",
        "            for level_idx, level in enumerate(processed_levels):\n",
        "                level['level_number'] = level_idx\n",
        "            \n",
        "            total_area_sqft = sum(r['bounds']['width'] * r['bounds']['height'] for l in processed_levels for r in l.get(\"rooms\", []))\n",
        "            \n",
        "            final_plan = {\n",
        "                \"input\": {\"basicDetails\": {\"prompt\": prompt_text, \"totalArea\": total_area_sqft, \"unit\": \"sqft\"}},\n",
        "                \"levels\": processed_levels, \"total_area\": round(total_area_sqft, 2),\n",
        "                \"construction_cost\": 0.0, \"materials\": {}, \"render_paths\": {}\n",
        "            }\n",
        "            \n",
        "            HouseOutput.model_validate(final_plan)\n",
        "            with open(output_file, 'w') as f: json.dump(final_plan, f, indent=2)\n",
        "            print(f\"‚úÖ SUCCESS! Saved validated plan to {output_file}\")\n",
        "\n",
        "        except ValidationError as e:\n",
        "            print(f\"‚ùå Stage 4 Failed: Pydantic validation error - {e}\")\n",
        "            with open(str(output_file).replace('.json', '_s4_failed_validation.json'), 'w') as f: json.dump(assembled_plan_dict, f, indent=2)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Stage 4 Failed: An unexpected error occurred - {e}\")\n",
        "            with open(str(output_file).replace('.json', '_s4_failed_exception.json'), 'w') as f: json.dump(assembled_plan_dict, f, indent=2)\n",
        "\n",
        "    print(\"\\nüéâ Data Factory run complete!\")\n",
        "else:\n",
        "    print(\"No prompts to process.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 4. (One-Time Setup) Generate Master Prompt File\n",
        "# @markdown This cell uses the `generate_prompts.py` script to create your master prompt file in Google Drive.\n",
        "# @markdown **You only need to run this cell once.**\n",
        "# @markdown Once the file is created, Cell 3 will be able to read from it for all future runs.\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Configuration ---\n",
        "#@markdown The desired location in your Google Drive for the master prompt file. This MUST match the path in Cell 3.\n",
        "DRIVE_PROMPT_FILE = \"/content/drive/MyDrive/housebrain_prompts/platinum_prompts.txt\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown The total number of prompts to generate for your master list.\n",
        "NUM_PROMPTS_TO_GENERATE = 30000 #@param {type:\"integer\"}\n",
        "# --- End Configuration ---\n",
        "\n",
        "# --- Execution ---\n",
        "REPO_DIR = \"/content/HouseBrainLLM\"\n",
        "script_path = os.path.join(REPO_DIR, \"scripts/generate_prompts.py\")\n",
        "\n",
        "# Ensure the repository is in the correct directory\n",
        "os.chdir(REPO_DIR)\n",
        "\n",
        "# Ensure the target directory in Drive exists\n",
        "Path(DRIVE_PROMPT_FILE).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Running prompt generation script to create {NUM_PROMPTS_TO_GENERATE} prompts...\")\n",
        "# Use an f-string for safer command construction\n",
        "command = f'python3 \"{script_path}\" --num-prompts {NUM_PROMPTS_TO_GENERATE} --output-file \"{DRIVE_PROMPT_FILE}\"'\n",
        "!{command}\n",
        "\n",
        "print(\"\\n--- Verification ---\")\n",
        "if Path(DRIVE_PROMPT_FILE).exists():\n",
        "    print(f\"‚úÖ Master prompt file successfully created at: {DRIVE_PROMPT_FILE}\")\n",
        "    print(\"First 5 prompts in the file:\")\n",
        "    !head -n 5 \"{DRIVE_PROMPT_FILE}\"\n",
        "else:\n",
        "    print(f\"‚ùå ERROR: Master prompt file was not created. Please check for errors above.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 5. (Optional) Download Generated Dataset\n",
        "# @markdown Run this cell after the data generation is complete to compress and download the entire output folder.\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "from datetime import datetime\n",
        "\n",
        "# Define the source directory in Google Drive. This should match DRIVE_OUTPUT_DIR from Cell 3.\n",
        "source_dir = \"/content/drive/MyDrive/housebrain_platinum_dataset\"\n",
        "\n",
        "# Create a timestamped zip filename\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "zip_filename = f\"housebrain_dataset_{timestamp}.zip\"\n",
        "zip_filepath = f\"/content/{zip_filename}\"\n",
        "\n",
        "if os.path.exists(source_dir) and os.listdir(source_dir):\n",
        "    # Create the zip archive\n",
        "    print(f\"Compressing '{source_dir}' into '{zip_filepath}'...\")\n",
        "    shutil.make_archive(zip_filepath.replace('.zip', ''), 'zip', source_dir)\n",
        "    print(\"‚úÖ Compression complete.\")\n",
        "\n",
        "    # Provide a download link\n",
        "    print(f\"\\nDownloading '{zip_filename}'...\")\n",
        "    files.download(zip_filepath)\n",
        "else:\n",
        "    print(f\"‚ùå ERROR: The source directory '{source_dir}' was not found or is empty. Please ensure the Data Factory ran correctly.\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
