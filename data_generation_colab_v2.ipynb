{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 1. Setup Environment\n",
        "# @markdown Mount Google Drive and clone the repository using a secure token.\n",
        "from google.colab import drive\n",
        "import os\n",
        "import getpass\n",
        "import subprocess\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"‚úÖ Google Drive mounted.\")\n",
        "\n",
        "# --- GitHub Setup ---\n",
        "#@markdown Enter your GitHub Personal Access Token (PAT) with repo access.\n",
        "GITHUB_TOKEN = getpass.getpass('Enter your GitHub PAT: ')\n",
        "REPO_URL = f\"https://{GITHUB_TOKEN}@github.com/Vinay-O/HouseBrainLLM.git\"\n",
        "REPO_DIR = \"/content/HouseBrainLLM\"\n",
        "\n",
        "# Clone the repository\n",
        "if os.path.exists(REPO_DIR):\n",
        "    print(\"Repository already exists. Pulling latest changes...\")\n",
        "    # Use subprocess.run for better error handling\n",
        "    subprocess.run(f\"cd {REPO_DIR} && git pull\", shell=True, check=True)\n",
        "else:\n",
        "    print(\"Cloning repository...\")\n",
        "    subprocess.run(f\"git clone {REPO_URL} {REPO_DIR}\", shell=True, check=True)\n",
        "\n",
        "print(\"‚úÖ Repository is ready.\")\n",
        "\n",
        "# --- Install Dependencies ---\n",
        "#@markdown Install necessary Python packages from the new requirements file.\n",
        "requirements_path = os.path.join(REPO_DIR, \"requirements.txt\")\n",
        "if os.path.exists(requirements_path):\n",
        "    print(\"Installing dependencies from requirements.txt...\")\n",
        "    !pip install -q -r {requirements_path}\n",
        "    print(\"‚úÖ Dependencies installed.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è requirements.txt not found. Installing default packages.\")\n",
        "    !pip install -q pydantic\n",
        "\n",
        "print(\"‚úÖ Environment setup complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 2. Configure and Start Ollama Server\n",
        "# @markdown This cell will download and start the Ollama server, then pull the specified model.\n",
        "# @markdown **NOTE:** A powerful model like `deepseek-r1:32b` is now recommended for higher quality results. It will be slower but more reliable.\n",
        "\n",
        "MODEL_NAME = \"deepseek-r1:32b\" # @param [\"deepseek-r1:32b\", \"llama3:70b-instruct\", \"qwen2:72b-instruct\", \"mixtral:instruct\"]\n",
        "\n",
        "# Download and start Ollama\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "import threading\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "def run_ollama():\n",
        "    try:\n",
        "        subprocess.run(\"ollama serve\", shell=True, check=True, capture_output=True, text=True)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Ollama server failed: {e.stderr}\")\n",
        "\n",
        "print(\"üöÄ Starting Ollama server in the background...\")\n",
        "ollama_thread = threading.Thread(target=run_ollama)\n",
        "ollama_thread.daemon = True\n",
        "ollama_thread.start()\n",
        "\n",
        "# Wait for the server to be ready\n",
        "print(\"‚è≥ Waiting for Ollama server to initialize...\")\n",
        "time.sleep(15) # Increased wait time for stability\n",
        "\n",
        "# Pull the model\n",
        "print(f\"üì¶ Pulling model: {MODEL_NAME}. This may take a while...\")\n",
        "try:\n",
        "    process = subprocess.run(\n",
        "        f\"ollama pull {MODEL_NAME}\",\n",
        "        shell=True, check=True, capture_output=True, text=True, timeout=900\n",
        "    )\n",
        "    print(f\"‚úÖ Model {MODEL_NAME} is ready.\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Error pulling model: {e.stderr}\")\n",
        "    print(\"This might happen if the model name is incorrect or the Ollama server is not ready.\")\n",
        "except subprocess.TimeoutExpired:\n",
        "    print(\"Timed out while pulling the model. The model might be very large or the connection slow.\")\n",
        "\n",
        "\n",
        "# Verify Ollama is running\n",
        "!ollama list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 3. Run the Data Factory (V4 - Self-Healing Pipeline)\n",
        "# @markdown This cell now uses a single-shot generation approach coupled with a powerful Python-based \"Schema Healer\" to fix errors deterministically.\n",
        "import sys\n",
        "import os\n",
        "import random\n",
        "import json\n",
        "import time\n",
        "import re\n",
        "from urllib.request import urlopen, Request\n",
        "from urllib.error import URLError, HTTPError\n",
        "from pydantic import ValidationError\n",
        "import hashlib\n",
        "\n",
        "# Add the cloned repo's src directory to the Python path\n",
        "REPO_DIR = \"/content/HouseBrainLLM\"\n",
        "sys.path.append(os.path.join(REPO_DIR, 'src'))\n",
        "try:\n",
        "    from housebrain.schema import HouseOutput, RoomType\n",
        "    print(\"‚úÖ Successfully imported HouseBrain schema.\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Failed to import HouseBrain schema: {e}\")\n",
        "\n",
        "# --- Configuration ---\n",
        "BATCH_SIZE = 10 # @param {type:\"integer\"}\n",
        "MASTER_PROMPT_LIST_PATH = \"/content/drive/MyDrive/housebrain_prompts/platinum_prompts.txt\" #@param {type:\"string\"}\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/housebrain_platinum_dataset\" # @param {type:\"string\"}\n",
        "MODEL_NAME = \"deepseek-r1:32b\" # This should match the model loaded in Cell 2\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "def generate_file_hash(prompt_text):\n",
        "    return hashlib.sha256(prompt_text.encode('utf-8')).hexdigest()[:16]\n",
        "\n",
        "# --- Master Prompt (Single-Shot) ---\n",
        "MASTER_PROMPT_TEMPLATE = \"\"\"\n",
        "You are a world-class architectural AI assistant. Your task is to generate a complete, valid house plan in a single JSON object based on the user's request.\n",
        "\n",
        "**CRITICAL INSTRUCTIONS:**\n",
        "1.  **Generate EVERYTHING at once:** You must output the entire house plan, including all levels, rooms, doors, and windows, in a single JSON response.\n",
        "2.  **Follow the Schema Loosely:** It is okay to use creative but descriptive field names (e.g., \"name\" for \"room_type\", or \"coordinates\" for \"bounds\"). Another script will fix them.\n",
        "3.  **Bounding Box Flexibility:** You can define room bounds using `{\"x\", \"y\", \"width\", \"height\"}` OR `{\"x1\", \"y1\", \"x2\", \"y2\"}`. The script will convert it.\n",
        "4.  **Output ONLY JSON:** Your entire response must be a single, raw JSON object. Do not include any text, markdown, or explanations before or after the JSON.\n",
        "\n",
        "**User Prompt:**\n",
        "{user_prompt}\n",
        "\n",
        "**Example JSON Structure (for guidance):**\n",
        "```json\n",
        "{{\n",
        "  \"levels\": [\n",
        "    {{\n",
        "      \"level_number\": 0,\n",
        "      \"name\": \"Ground Floor\",\n",
        "      \"rooms\": [\n",
        "        {{\n",
        "          \"id\": \"living_room_0\",\n",
        "          \"name\": \"Living Room\",\n",
        "          \"bounds\": {{\"x1\": 0, \"y1\": 0, \"x2\": 20, \"y2\": 15}},\n",
        "          \"doors\": [ ... ],\n",
        "          \"windows\": [ ... ]\n",
        "        }}\n",
        "      ]\n",
        "    }}\n",
        "  ]\n",
        "}}\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def call_ollama_colab(model, prompt, max_retries=3, delay=5):\n",
        "    # (This function remains the same as before)\n",
        "    OLLAMA_ENDPOINT = \"http://localhost:11434/api/generate\"\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    data = {\"model\": model, \"prompt\": prompt, \"stream\": False}\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            req = Request(OLLAMA_ENDPOINT, data=json.dumps(data).encode(\"utf-8\"), headers=headers, method=\"POST\")\n",
        "            with urlopen(req) as response:\n",
        "                response_body = response.read().decode(\"utf-8\")\n",
        "                response_json = json.loads(response_body)\n",
        "                return response_json.get(\"response\", \"\").strip()\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR calling Ollama on attempt {attempt + 1}: {e}\")\n",
        "            if attempt < max_retries - 1: time.sleep(delay)\n",
        "    return None\n",
        "\n",
        "def repair_json(text):\n",
        "    \"\"\"Aggressively finds and parses the first JSON object from a string.\"\"\"\n",
        "    print(\"Attempting to extract JSON from model output...\")\n",
        "    match = re.search(r'\\{[\\s\\S]*\\}', text)\n",
        "    if not match:\n",
        "        print(\"‚ùå No JSON object found in the text.\")\n",
        "        return None\n",
        "    try:\n",
        "        parsed = json.loads(match.group(0))\n",
        "        print(\"‚úÖ Successfully extracted and parsed JSON.\")\n",
        "        return parsed\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"‚ùå Failed to parse the extracted JSON blob: {e}\")\n",
        "        return None\n",
        "\n",
        "def heal_and_convert_plan(raw_plan):\n",
        "    \"\"\"\n",
        "    This is the \"Schema Healer\". It takes a raw, potentially malformed JSON\n",
        "    object from the LLM and ruthlessly converts it into a valid schema.\n",
        "    \"\"\"\n",
        "    healed_plan = {\"levels\": []}\n",
        "    if not isinstance(raw_plan.get(\"levels\"), list):\n",
        "        return healed_plan # Cannot proceed without a list of levels\n",
        "\n",
        "    # --- Room Type Mapping ---\n",
        "    # Maps common, creative names to the strict schema Enum\n",
        "    ROOM_TYPE_MAP = {\n",
        "        \"living room\": RoomType.LIVING_ROOM, \"livingroom\": RoomType.LIVING_ROOM,\n",
        "        \"dining room\": RoomType.DINING_ROOM, \"dining area\": RoomType.DINING_ROOM,\n",
        "        \"kitchen\": RoomType.KITCHEN,\n",
        "        \"master bedroom\": RoomType.MASTER_BEDROOM, \"master bdrm\": RoomType.MASTER_BEDROOM,\n",
        "        \"bedroom\": RoomType.BEDROOM, \"bdrm\": RoomType.BEDROOM,\n",
        "        \"bathroom\": RoomType.BATHROOM, \"bath\": RoomType.BATHROOM,\n",
        "        \"half bath\": RoomType.HALF_BATH, \"powder room\": RoomType.HALF_BATH,\n",
        "        \"study\": RoomType.STUDY, \"office\": RoomType.STUDY, \"home office\": RoomType.STUDY,\n",
        "        \"garage\": RoomType.GARAGE,\n",
        "        \"utility\": RoomType.UTILITY, \"laundry\": RoomType.UTILITY,\n",
        "        \"storage\": RoomType.STORAGE, \"closet\": RoomType.STORAGE,\n",
        "        \"corridor\": RoomType.CORRIDOR, \"hallway\": RoomType.CORRIDOR,\n",
        "        \"entrance\": RoomType.ENTRANCE, \"entry\": RoomType.ENTRANCE, \"foyer\": RoomType.ENTRANCE,\n",
        "        \"balcony\": RoomType.BALCONY,\n",
        "        \"verandah\": RoomType.VERANDAH,\n",
        "    }\n",
        "\n",
        "    for i, raw_level in enumerate(raw_plan[\"levels\"]):\n",
        "        healed_level = {\n",
        "            # Heal: Invent 'level_number' if missing, or find it in 'level' or 'floor'\n",
        "            \"level_number\": raw_level.get(\"level_number\", raw_level.get(\"level\", raw_level.get(\"floor\", i))),\n",
        "            \"rooms\": []\n",
        "        }\n",
        "\n",
        "        if not isinstance(raw_level.get(\"rooms\"), list): continue\n",
        "\n",
        "        for raw_room in raw_level[\"rooms\"]:\n",
        "            healed_room = {}\n",
        "            \n",
        "            # Heal: Find 'id'\n",
        "            healed_room[\"id\"] = raw_room.get(\"id\", f\"room_{i}_{len(healed_level['rooms'])}\")\n",
        "\n",
        "            # Heal: Find and map 'room_type' from 'name' or 'type'\n",
        "            room_name = str(raw_room.get(\"name\", raw_room.get(\"type\", \"\"))).lower().strip()\n",
        "            healed_room[\"type\"] = ROOM_TYPE_MAP.get(room_name, RoomType.STORAGE) # Default to storage if unknown\n",
        "\n",
        "            # Heal: Convert bounds from x1/y1/x2/y2 to x/y/width/height if necessary\n",
        "            raw_bounds = raw_room.get(\"bounds\", raw_room.get(\"coordinates\", {}))\n",
        "            if \"x1\" in raw_bounds and \"x2\" in raw_bounds:\n",
        "                healed_bounds = {\n",
        "                    \"x\": raw_bounds[\"x1\"],\n",
        "                    \"y\": raw_bounds[\"y1\"],\n",
        "                    \"width\": abs(raw_bounds[\"x2\"] - raw_bounds[\"x1\"]),\n",
        "                    \"height\": abs(raw_bounds[\"y2\"] - raw_bounds[\"y1\"]),\n",
        "                }\n",
        "            else:\n",
        "                healed_bounds = raw_bounds # Assume it's already in the correct format\n",
        "            \n",
        "            healed_room[\"bounds\"] = healed_bounds\n",
        "            healed_room[\"doors\"] = raw_room.get(\"doors\", [])\n",
        "            healed_room[\"windows\"] = raw_room.get(\"windows\", [])\n",
        "            \n",
        "            healed_level[\"rooms\"].append(healed_room)\n",
        "        healed_plan[\"levels\"].append(healed_level)\n",
        "        \n",
        "    print(f\"‚úÖ Schema healing complete. Processed {len(healed_plan['levels'])} levels.\")\n",
        "    return healed_plan\n",
        "\n",
        "# --- Execution ---\n",
        "\n",
        "print(\"--- Starting Data Factory Run (V4 - Self-Healing Pipeline) ---\")\n",
        "try:\n",
        "    with open(MASTER_PROMPT_LIST_PATH, 'r') as f:\n",
        "        master_prompt_list = f.read().splitlines()\n",
        "    print(f\"‚úÖ Found {len(master_prompt_list)} total prompts.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå ERROR: Master prompt list not found at '{MASTER_PROMPT_LIST_PATH}'\")\n",
        "    master_prompt_list = []\n",
        "\n",
        "if master_prompt_list:\n",
        "    prompts_to_process = random.sample(master_prompt_list, min(BATCH_SIZE, len(master_prompt_list)))\n",
        "    print(f\"‚úÖ This run will process a random batch of {len(prompts_to_process)} prompts.\")\n",
        "\n",
        "    for i, prompt_text in enumerate(prompts_to_process):\n",
        "        print(f\"\\n================== PROMPT {i+1}/{len(prompts_to_process)} ==================\")\n",
        "        file_hash = generate_file_hash(prompt_text)\n",
        "        output_path = os.path.join(OUTPUT_DIR, f\"plan_{file_hash}.json\")\n",
        "        \n",
        "        # Skip if this prompt has already been processed to avoid duplicate work\n",
        "        if os.path.exists(output_path):\n",
        "            print(f\"‚è≠Ô∏è Skipping prompt, plan already exists: {output_path}\")\n",
        "            continue\n",
        "\n",
        "        print(prompt_text[:120] + \"...\" if len(prompt_text) > 120 else prompt_text)\n",
        "        print(\"--------------------------------------------------\")\n",
        "\n",
        "        # --- STAGE 1: Single-Shot Generation ---\n",
        "        print(\"Running Stage 1: Single-Shot Generation...\")\n",
        "        master_prompt = MASTER_PROMPT_TEMPLATE.format(user_prompt=prompt_text)\n",
        "        llm_output = call_ollama_colab(MODEL_NAME, master_prompt)\n",
        "        if not llm_output:\n",
        "            print(\"‚ùå Stage 1 Failed: No response from model.\"); continue\n",
        "        \n",
        "        raw_plan_data = repair_json(llm_output)\n",
        "        if not raw_plan_data:\n",
        "            print(\"‚ùå Stage 1 Failed: Could not extract a valid JSON object.\"); continue\n",
        "\n",
        "        # --- STAGE 2: Python Schema Healer ---\n",
        "        print(\"Running Stage 2: Healing and Converting Schema...\")\n",
        "        healed_plan = heal_and_convert_plan(raw_plan_data)\n",
        "        \n",
        "        # --- STAGE 3: Final Assembly & Validation ---\n",
        "        print(\"Running Stage 3: Assembling and Validating...\")\n",
        "        try:\n",
        "            # Calculate metadata from the healed plan\n",
        "            calculated_area, bedroom_count, bathroom_count = 0.0, 0, 0\n",
        "            for level in healed_plan.get('levels', []):\n",
        "                for room in level.get('rooms', []):\n",
        "                    bounds = room.get('bounds', {})\n",
        "                    w, h = bounds.get('width', 0), bounds.get('height', 0)\n",
        "                    calculated_area += w * h\n",
        "                    if room.get('type') in [RoomType.BEDROOM, RoomType.MASTER_BEDROOM]: bedroom_count += 1\n",
        "                    if room.get('type') in [RoomType.BATHROOM, RoomType.HALF_BATH]: bathroom_count += 1\n",
        "\n",
        "            # Construct the final object for Pydantic validation\n",
        "            final_plan_for_validation = {\n",
        "                \"input\": {\n",
        "                    \"basicDetails\": {\n",
        "                        \"prompt\": prompt_text, \"totalArea\": calculated_area, \"unit\": \"sqft\",\n",
        "                        \"floors\": len(healed_plan.get('levels', [])), \"bedrooms\": bedroom_count,\n",
        "                        \"bathrooms\": bathroom_count, \"style\": \"unknown\", \"budget\": 0\n",
        "                    }, \"plot\": {}, \"roomBreakdown\": []\n",
        "                },\n",
        "                \"levels\": healed_plan.get(\"levels\", []),\n",
        "                \"total_area\": calculated_area, \"construction_cost\": 0.0\n",
        "            }\n",
        "            \n",
        "            # The final gate: Pydantic validation\n",
        "            validated_plan = HouseOutput.model_validate(final_plan_for_validation)\n",
        "            \n",
        "            with open(output_path, 'w') as f:\n",
        "                f.write(validated_plan.model_dump_json(indent=2))\n",
        "            print(f\"‚úÖ SUCCESS! Saved validated plan to {output_path}\")\n",
        "\n",
        "        except ValidationError as e:\n",
        "            print(f\"‚ùå Stage 3 Failed: Pydantic validation error AFTER healing:\\n{e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Stage 3 Failed: An unexpected error occurred - {type(e).__name__}: {e}\")\n",
        "\n",
        "print(\"\\nüéâ Data Factory run complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 4. (One-Time Setup) Generate Master Prompt File\n",
        "# @markdown This cell uses the `generate_prompts.py` script to create your master prompt file in Google Drive.\n",
        "# @markdown **You only need to run this cell once.**\n",
        "# @markdown Once the file is created, Cell 3 will be able to read from it for all future runs.\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Configuration ---\n",
        "#@markdown The desired location in your Google Drive for the master prompt file. This MUST match the path in Cell 3.\n",
        "DRIVE_PROMPT_FILE = \"/content/drive/MyDrive/housebrain_prompts/platinum_prompts.txt\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown The total number of prompts to generate for your master list.\n",
        "NUM_PROMPTS_TO_GENERATE = 40000 #@param {type:\"integer\"}\n",
        "# --- End Configuration ---\n",
        "\n",
        "# --- Execution ---\n",
        "# REPO_DIR is inherited from Cell 1\n",
        "script_path = os.path.join(REPO_DIR, \"scripts/generate_prompts.py\")\n",
        "\n",
        "# Ensure the repository is in the correct directory\n",
        "os.chdir(REPO_DIR)\n",
        "\n",
        "# Ensure the target directory in Drive exists\n",
        "Path(DRIVE_PROMPT_FILE).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Running prompt generation script to create {NUM_PROMPTS_TO_GENERATE} prompts...\")\n",
        "# Use an f-string for safer command construction\n",
        "command = f'python3 \"{script_path}\" --num-prompts {NUM_PROMPTS_TO_GENERATE} --output-file \"{DRIVE_PROMPT_FILE}\"'\n",
        "!{command}\n",
        "\n",
        "print(\"\\n--- Verification ---\")\n",
        "if Path(DRIVE_PROMPT_FILE).exists():\n",
        "    print(f\"‚úÖ Master prompt file successfully created at: {DRIVE_PROMPT_FILE}\")\n",
        "    print(\"First 5 prompts in the file:\")\n",
        "    !head -n 5 \"{DRIVE_PROMPT_FILE}\"\n",
        "else:\n",
        "    print(f\"‚ùå ERROR: Master prompt file was not created. Please check for errors above.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 5. (Optional) Download Generated Dataset\n",
        "# @markdown Run this cell after the data generation is complete to compress and download the entire output folder.\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "from datetime import datetime\n",
        "\n",
        "# Define the source directory in Google Drive. This should match OUTPUT_DIR from Cell 3.\n",
        "# We define it here again to make this cell self-contained.\n",
        "source_dir = \"/content/drive/MyDrive/housebrain_platinum_dataset\"\n",
        "\n",
        "# Create a timestamped zip filename\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "zip_filename = f\"housebrain_dataset_{timestamp}.zip\"\n",
        "zip_filepath = f\"/content/{zip_filename}\"\n",
        "\n",
        "if os.path.exists(source_dir) and os.listdir(source_dir):\n",
        "    # Create the zip archive\n",
        "    print(f\"Compressing '{source_dir}' into '{zip_filepath}'...\")\n",
        "    shutil.make_archive(zip_filepath.replace('.zip', ''), 'zip', source_dir)\n",
        "    print(\"‚úÖ Compression complete.\")\n",
        "\n",
        "    # Provide a download link\n",
        "    print(f\"\\nDownloading '{zip_filename}'...\")\n",
        "    files.download(zip_filepath)\n",
        "else:\n",
        "    print(f\"‚ùå ERROR: The source directory '{source_dir}' was not found or is empty. Please ensure the Data Factory ran correctly.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
