{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 1. Setup Environment\n",
        "# @markdown Mount Google Drive and clone the repository using a secure token.\n",
        "from google.colab import drive\n",
        "import os\n",
        "import getpass\n",
        "import subprocess\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"‚úÖ Google Drive mounted.\")\n",
        "\n",
        "# --- GitHub Setup ---\n",
        "#@markdown Enter your GitHub Personal Access Token (PAT) with repo access.\n",
        "GITHUB_TOKEN = getpass.getpass('Enter your GitHub PAT: ')\n",
        "REPO_URL = f\"https://{GITHUB_TOKEN}@github.com/Vinay-O/HouseBrainLLM.git\"\n",
        "REPO_DIR = \"/content/HouseBrainLLM\"\n",
        "\n",
        "# Clone the repository\n",
        "if os.path.exists(REPO_DIR):\n",
        "    print(\"Repository already exists. Pulling latest changes...\")\n",
        "    # Use subprocess.run for better error handling\n",
        "    subprocess.run(f\"cd {REPO_DIR} && git pull\", shell=True, check=True)\n",
        "else:\n",
        "    print(\"Cloning repository...\")\n",
        "    subprocess.run(f\"git clone {REPO_URL} {REPO_DIR}\", shell=True, check=True)\n",
        "\n",
        "print(\"‚úÖ Repository is ready.\")\n",
        "\n",
        "# --- Install Dependencies ---\n",
        "#@markdown Install necessary Python packages from the new requirements file.\n",
        "requirements_path = os.path.join(REPO_DIR, \"requirements.txt\")\n",
        "if os.path.exists(requirements_path):\n",
        "    print(\"Installing dependencies from requirements.txt...\")\n",
        "    !pip install -q -r {requirements_path}\n",
        "    print(\"‚úÖ Dependencies installed.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è requirements.txt not found. Installing default packages.\")\n",
        "    !pip install -q pydantic\n",
        "\n",
        "print(\"‚úÖ Environment setup complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 2. Configure and Start Ollama Server\n",
        "# @markdown This cell will download and start the Ollama server, then pull the specified model.\n",
        "# @markdown **NOTE:** A powerful model like `deepseek-r1:32b` is now recommended for higher quality results. It will be slower but more reliable.\n",
        "\n",
        "MODEL_NAME = \"deepseek-r1:32b\" # @param [\"deepseek-r1:32b\", \"llama3:70b-instruct\", \"qwen2:72b-instruct\", \"mixtral:instruct\"]\n",
        "\n",
        "# Download and start Ollama\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "import threading\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "def run_ollama():\n",
        "    try:\n",
        "        subprocess.run(\"ollama serve\", shell=True, check=True, capture_output=True, text=True)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Ollama server failed: {e.stderr}\")\n",
        "\n",
        "print(\"üöÄ Starting Ollama server in the background...\")\n",
        "ollama_thread = threading.Thread(target=run_ollama)\n",
        "ollama_thread.daemon = True\n",
        "ollama_thread.start()\n",
        "\n",
        "# Wait for the server to be ready\n",
        "print(\"‚è≥ Waiting for Ollama server to initialize...\")\n",
        "time.sleep(15) # Increased wait time for stability\n",
        "\n",
        "# Pull the model\n",
        "print(f\"üì¶ Pulling model: {MODEL_NAME}. This may take a while...\")\n",
        "try:\n",
        "    process = subprocess.run(\n",
        "        f\"ollama pull {MODEL_NAME}\",\n",
        "        shell=True, check=True, capture_output=True, text=True, timeout=900\n",
        "    )\n",
        "    print(f\"‚úÖ Model {MODEL_NAME} is ready.\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Error pulling model: {e.stderr}\")\n",
        "    print(\"This might happen if the model name is incorrect or the Ollama server is not ready.\")\n",
        "except subprocess.TimeoutExpired:\n",
        "    print(\"Timed out while pulling the model. The model might be very large or the connection slow.\")\n",
        "\n",
        "\n",
        "# Verify Ollama is running\n",
        "!ollama list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 3. Run the Data Factory\n",
        "# @markdown This cell is the core of the data generation process. It reads from the master prompt list and runs the \"Assembly Line\" process for each prompt.\n",
        "import sys\n",
        "import os\n",
        "import random\n",
        "import json\n",
        "import time\n",
        "import re\n",
        "from urllib.request import urlopen, Request\n",
        "from urllib.error import URLError, HTTPError\n",
        "from pydantic import ValidationError\n",
        "import hashlib\n",
        "\n",
        "# Add the cloned repo's src directory to the Python path to import the schema\n",
        "# REPO_DIR is inherited from Cell 1\n",
        "sys.path.append(os.path.join(REPO_DIR, 'src'))\n",
        "try:\n",
        "    from housebrain.schema import HouseOutput\n",
        "    print(\"‚úÖ Successfully imported HouseBrain schema.\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Failed to import HouseBrain schema: {e}\")\n",
        "\n",
        "# --- Configuration ---\n",
        "BATCH_SIZE = 10 # @param {type:\"integer\"}\n",
        "MASTER_PROMPT_LIST_PATH = \"/content/drive/MyDrive/housebrain_prompts/platinum_prompts.txt\" #@param {type:\"string\"}\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/housebrain_platinum_dataset\" # @param {type:\"string\"}\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "def generate_file_hash(prompt_text):\n",
        "    \"\"\"Creates a unique and consistent hash for a given prompt text.\"\"\"\n",
        "    return hashlib.sha256(prompt_text.encode('utf-8')).hexdigest()[:16]\n",
        "\n",
        "# --- Prompts ---\n",
        "\n",
        "STAGE_1_LAYOUT_PROMPT = \"\"\"\n",
        "You are an expert architectural AI. Your task is to generate the foundational layout for a house based on a user's prompt.\n",
        "**Instructions:**\n",
        "1.  **Analyze the Request:** Carefully read the user's prompt to understand the constraints (e.g., plot size, number of floors, total area, number of rooms).\n",
        "2.  **Design the Layout:** Create a logical and functional floor plan. Ensure rooms are reasonably sized and placed.\n",
        "3.  **Define Levels and Rooms:** Structure your output with levels (e.g., ground floor, first floor) and the rooms within each level.\n",
        "4.  **Specify Room Bounds:** For each room, define its `bounds` as a rectangle with `x`, `y`, `width`, and `height`. The origin (0,0) is the top-left corner of the plot.\n",
        "5.  **Adhere to the Schema:** The output MUST be a single JSON object that validates against the `HouseOutput` schema, but **ONLY include the `levels` and `rooms`**. Do NOT include `doors` or `windows` at this stage.\n",
        "6.  **Use Unique IDs:** Assign a unique string `id` to every level and every room (e.g., \"level_0\", \"room_0\", \"kitchen_0\").\n",
        "**User Prompt:**\n",
        "{user_prompt}\n",
        "**Output Format (JSON Object only):**\n",
        "```json\n",
        "{{\n",
        "  \"levels\": [\n",
        "    {{\n",
        "      \"id\": \"level_0\",\n",
        "      \"level_number\": 0,\n",
        "      \"rooms\": [\n",
        "        {{ \"id\": \"living_room_0\", \"room_type\": \"living_room\", \"bounds\": {{\"x\": 0, \"y\": 0, \"width\": 20, \"height\": 15}} }},\n",
        "        {{ \"id\": \"kitchen_0\", \"room_type\": \"kitchen\", \"bounds\": {{\"x\": 20, \"y\": 0, \"width\": 10, \"height\": 15}} }}\n",
        "      ]\n",
        "    }}\n",
        "  ]\n",
        "}}\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "STAGE_2_DOORS_PROMPT = \"\"\"\n",
        "You are an expert architectural AI. You will be given a JSON object describing a house layout. Your task is to add doors to this layout.\n",
        "\n",
        "**CRITICAL INSTRUCTIONS:**\n",
        "1.  **Your output MUST be ONLY a valid JSON list of Door objects.**\n",
        "2.  **DO NOT write ANY text, explanation, or markdown before or after the JSON list.** Your response will be parsed by a program and will fail if any extra text is present.\n",
        "3.  **Analyze the Layout:** Review the provided rooms and their adjacencies.\n",
        "4.  **Place Doors Logically:** Every room must be accessible. Add an exterior door for the main entrance. Connect adjacent rooms.\n",
        "5.  **Adhere to the Schema:** Each door object must have `position`, `width`, `type`, `room1`, and `room2`.\n",
        "6.  **Avoid Common JSON Errors:** Do not use trailing commas. Ensure all strings are enclosed in double quotes.\n",
        "\n",
        "**House Layout:**\n",
        "{layout_json}\n",
        "\n",
        "**MULTIPLE EXAMPLES of correct door objects:**\n",
        "- An exterior front door: `{{\"position\": {{\"x\": 0, \"y\": 7}}, \"width\": 3.5, \"type\": \"exterior\", \"room1\": \"entrance_0\", \"room2\": \"exterior_front\"}}`\n",
        "- A standard interior door: `{{\"position\": {{\"x\": 10, \"y\": 7}}, \"width\": 3, \"type\": \"interior\", \"room1\": \"entrance_0\", \"room2\": \"living_room_0\"}}`\n",
        "- A sliding door to a balcony: `{{\"position\": {{\"x\": 15, \"y\": 0}}, \"width\": 6, \"type\": \"sliding\", \"room1\": \"master_bedroom_0\", \"room2\": \"balcony_0\"}}`\n",
        "\n",
        "**Final Output Format (A raw JSON list ONLY):**\n",
        "```json\n",
        "[\n",
        "  {{ ... door object 1 ... }},\n",
        "  {{ ... door object 2 ... }}\n",
        "]\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "STAGE_3_WINDOWS_PROMPT = \"\"\"\n",
        "You are an expert architectural AI. You will be given a JSON object describing a house layout. Your task is to add windows to this layout.\n",
        "\n",
        "**CRITICAL INSTRUCTIONS:**\n",
        "1.  **Your output MUST be ONLY a valid JSON list of Window objects.**\n",
        "2.  **DO NOT write ANY text, explanation, or markdown before or after the JSON list.** Your response will be parsed by a program and will fail if any extra text is present.\n",
        "3.  **Analyze the Layout:** Review the provided rooms.\n",
        "4.  **Place Windows Logically:** Add windows to exterior walls. Living rooms and bedrooms should have good lighting.\n",
        "5.  **Adhere to the Schema:** Each window object must have `position`, `width`, `height`, `type`, and `room_id`.\n",
        "6.  **Avoid Common JSON Errors:** Do not use trailing commas. Ensure all strings are enclosed in double quotes.\n",
        "\n",
        "**House Layout:**\n",
        "{layout_json}\n",
        "\n",
        "**MULTIPLE EXAMPLES of correct window objects:**\n",
        "- A large bay window: `{{\"position\": {{\"x\": 5, \"y\": 0}}, \"width\": 8, \"height\": 5, \"type\": \"bay\", \"room_id\": \"living_room_0\"}}`\n",
        "- A standard sliding window: `{{\"position\": {{\"x\": 25, \"y\": 0}}, \"width\": 4, \"height\": 3, \"type\": \"sliding\", \"room_id\": \"kitchen_0\"}}`\n",
        "- A small fixed window for a bathroom: `{{\"position\": {{\"x\": 3, \"y\": 15}}, \"width\": 2, \"height\": 2, \"type\": \"fixed\", \"room_id\": \"bathroom_0\"}}`\n",
        "\n",
        "**Final Output Format (A raw JSON list ONLY):**\n",
        "```json\n",
        "[\n",
        "  {{ ... window object 1 ... }},\n",
        "  {{ ... window object 2 ... }}\n",
        "]\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def call_ollama_colab(model, prompt, max_retries=3, delay=5):\n",
        "    \"\"\"Function to call the Ollama API running on Google Colab.\"\"\"\n",
        "    OLLAMA_ENDPOINT = \"http://localhost:11434/api/generate\"\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    data = {\"model\": model, \"prompt\": prompt, \"stream\": False}\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            req = Request(OLLAMA_ENDPOINT, data=json.dumps(data).encode(\"utf-8\"), headers=headers, method=\"POST\")\n",
        "            with urlopen(req) as response:\n",
        "                response_body = response.read().decode(\"utf-8\")\n",
        "                response_json = json.loads(response_body)\n",
        "                return response_json.get(\"response\", \"\").strip()\n",
        "        except (URLError, HTTPError, ConnectionResetError) as e:\n",
        "            print(f\"ERROR: Ollama connection error on attempt {attempt + 1}/{max_retries}: {e}\")\n",
        "            if attempt < max_retries - 1:\n",
        "                time.sleep(delay)\n",
        "            else:\n",
        "                return None\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR: Unexpected error calling Ollama: {e}\")\n",
        "            return None\n",
        "\n",
        "def repair_json(text, target_type=dict):\n",
        "    \"\"\"Aggressively finds and parses a JSON object or list from a string.\"\"\"\n",
        "    text = str(text)\n",
        "    start_char, end_char = ('[', ']') if target_type == list else ('{', '}')\n",
        "    try:\n",
        "        parsed = json.loads(text)\n",
        "        if isinstance(parsed, target_type):\n",
        "            print(\"‚úÖ Initial parse successful.\")\n",
        "            return parsed\n",
        "    except json.JSONDecodeError:\n",
        "        pass\n",
        "    print(f\"Initial parse for type {target_type.__name__} failed. Attempting aggressive extraction...\")\n",
        "    pattern = re.compile(f'\\\\{start_char}[\\\\s\\\\S]*\\\\{end_char}')\n",
        "    match = pattern.search(text)\n",
        "    if not match:\n",
        "        print(f\"‚ùå No JSON structure of type {target_type.__name__} found.\")\n",
        "        return None\n",
        "    potential_json = match.group(0)\n",
        "    try:\n",
        "        parsed = json.loads(potential_json)\n",
        "        if isinstance(parsed, target_type):\n",
        "            print(f\"‚úÖ Successfully extracted and parsed JSON of type {target_type.__name__}.\")\n",
        "            return parsed\n",
        "        if target_type == list and isinstance(parsed, dict):\n",
        "            for key, value in parsed.items():\n",
        "                if isinstance(value, list):\n",
        "                    print(f\"‚úÖ Repaired JSON by extracting list from key '{key}'.\")\n",
        "                    return value\n",
        "        print(f\"‚ùå Extracted JSON is not of the target type {target_type.__name__}.\")\n",
        "        return None\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"‚ùå Failed to parse the extracted JSON blob: {e}\")\n",
        "        return None\n",
        "\n",
        "def assemble_plan(layout_dict, doors_list, windows_list):\n",
        "    \"\"\"A completely bulletproof assembly function that can handle any malformed data.\"\"\"\n",
        "    def safe_get(d, key, default=None):\n",
        "        try:\n",
        "            return d.get(key, default) if isinstance(d, dict) else default\n",
        "        except:\n",
        "            return default\n",
        "    result = {\"levels\": []}\n",
        "    try:\n",
        "        if not isinstance(layout_dict, dict): return result\n",
        "        levels = safe_get(layout_dict, \"levels\", [])\n",
        "        if not isinstance(levels, list): return result\n",
        "        result[\"levels\"] = levels\n",
        "        rooms_by_id = {}\n",
        "        for level in levels:\n",
        "            if not isinstance(level, dict): continue\n",
        "            level[\"rooms\"] = [] if \"rooms\" not in level or not isinstance(level[\"rooms\"], list) else level[\"rooms\"]\n",
        "            for room in level[\"rooms\"]:\n",
        "                if not isinstance(room, dict): continue\n",
        "                room_id = safe_get(room, \"id\")\n",
        "                if not isinstance(room_id, str): continue\n",
        "                room[\"doors\"] = [] if \"doors\" not in room or not isinstance(room[\"doors\"], list) else room[\"doors\"]\n",
        "                room[\"windows\"] = [] if \"windows\" not in room or not isinstance(room[\"windows\"], list) else room[\"windows\"]\n",
        "                rooms_by_id[room_id] = room\n",
        "        if isinstance(windows_list, list):\n",
        "            for window in windows_list:\n",
        "                if not isinstance(window, dict): continue\n",
        "                room_id = safe_get(window, \"room_id\")\n",
        "                if isinstance(room_id, str) and room_id in rooms_by_id:\n",
        "                    rooms_by_id[room_id][\"windows\"].append(window)\n",
        "        if isinstance(doors_list, list):\n",
        "            for door in doors_list:\n",
        "                if not isinstance(door, dict): continue\n",
        "                room1_id = safe_get(door, \"room1\")\n",
        "                if isinstance(room1_id, str) and room1_id in rooms_by_id:\n",
        "                    rooms_by_id[room1_id][\"doors\"].append(door)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Assembly Error: {e}\")\n",
        "    return result\n",
        "\n",
        "# --- Execution ---\n",
        "\n",
        "print(\"--- Starting Data Factory Run (V3: Assembly Line) ---\")\n",
        "try:\n",
        "    with open(MASTER_PROMPT_LIST_PATH, 'r') as f:\n",
        "        master_prompt_list = f.read().splitlines()\n",
        "    print(f\"‚úÖ Found {len(master_prompt_list)} total prompts.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå ERROR: Master prompt list not found at '{MASTER_PROMPT_LIST_PATH}'\")\n",
        "    master_prompt_list = []\n",
        "\n",
        "if master_prompt_list:\n",
        "    prompts_to_process = random.sample(master_prompt_list, min(BATCH_SIZE, len(master_prompt_list)))\n",
        "    print(f\"‚úÖ This run will process a random batch of {len(prompts_to_process)} prompts.\")\n",
        "\n",
        "    for i, prompt_text in enumerate(prompts_to_process):\n",
        "        print(f\"\\n================== PROMPT {i+1}/{len(prompts_to_process)} ==================\")\n",
        "        print(prompt_text[:120] + \"...\" if len(prompt_text) > 120 else prompt_text)\n",
        "        print(\"--------------------------------------------------\")\n",
        "\n",
        "        # STAGE 1\n",
        "        print(\"Running Stage 1: Layout Generation...\")\n",
        "        stage_1_response = call_ollama_colab(MODEL_NAME, STAGE_1_LAYOUT_PROMPT.format(user_prompt=prompt_text))\n",
        "        if not stage_1_response: print(\"‚ùå Stage 1 Failed: No response from model.\"); continue\n",
        "        layout_data = repair_json(stage_1_response, target_type=dict)\n",
        "        if not layout_data: print(\"‚ùå Stage 1 Failed: Could not produce a valid layout JSON.\"); continue\n",
        "\n",
        "        # STAGE 2\n",
        "        print(\"Running Stage 2: Door Generation...\")\n",
        "        stage_2_response = call_ollama_colab(MODEL_NAME, STAGE_2_DOORS_PROMPT.format(layout_json=json.dumps(layout_data, indent=2)))\n",
        "        if not stage_2_response: print(\"‚ùå Stage 2 Failed: No response from model.\"); continue\n",
        "        doors_data = repair_json(stage_2_response, target_type=list)\n",
        "        if doors_data is None: print(\"‚ùå Stage 2 Failed: Could not produce a valid list of doors.\"); continue\n",
        "\n",
        "        # STAGE 3\n",
        "        print(\"Running Stage 3: Window Generation...\")\n",
        "        stage_3_response = call_ollama_colab(MODEL_NAME, STAGE_3_WINDOWS_PROMPT.format(layout_json=json.dumps(layout_data, indent=2)))\n",
        "        if not stage_3_response: print(\"‚ùå Stage 3 Failed: No response from model.\"); continue\n",
        "        windows_data = repair_json(stage_3_response, target_type=list)\n",
        "        if windows_data is None: print(\"‚ùå Stage 3 Failed: Could not produce a valid list of windows.\"); continue\n",
        "\n",
        "        # STAGE 4\n",
        "        print(\"Running Stage 4: Assembling and Validating...\")\n",
        "        try:\n",
        "            assembled_layout = assemble_plan(layout_data, doors_data, windows_data)\n",
        "            calculated_area, bedroom_count, bathroom_count = 0.0, 0, 0\n",
        "            if isinstance(assembled_layout.get('levels'), list):\n",
        "                for level in assembled_layout.get('levels', []):\n",
        "                    if isinstance(level.get('rooms'), list):\n",
        "                        for room in level.get('rooms', []):\n",
        "                            if isinstance(room, dict):\n",
        "                                bounds = room.get('bounds', {})\n",
        "                                if isinstance(bounds, dict):\n",
        "                                    w, h = bounds.get('width', 0), bounds.get('height', 0)\n",
        "                                    calculated_area += w * h if isinstance(w, (int, float)) and isinstance(h, (int, float)) else 0\n",
        "                                room_type = room.get('type')\n",
        "                                if room_type in [\"bedroom\", \"master_bedroom\"]: bedroom_count += 1\n",
        "                                if room_type in [\"bathroom\", \"half_bath\"]: bathroom_count += 1\n",
        "            \n",
        "            final_plan_dict = {\n",
        "                \"input\": {\n",
        "                    \"basicDetails\": {\n",
        "                        \"prompt\": prompt_text, \"totalArea\": calculated_area, \"unit\": \"sqft\",\n",
        "                        \"floors\": len(assembled_layout.get('levels', [])), \"bedrooms\": bedroom_count,\n",
        "                        \"bathrooms\": bathroom_count, \"style\": \"unknown\", \"budget\": 0\n",
        "                    },\n",
        "                    \"plot\": {}, \"roomBreakdown\": []\n",
        "                },\n",
        "                \"levels\": assembled_layout.get(\"levels\", []),\n",
        "                \"total_area\": calculated_area, \"construction_cost\": 0.0\n",
        "            }\n",
        "            validated_plan = HouseOutput.model_validate(final_plan_dict)\n",
        "            file_hash = generate_file_hash(prompt_text)\n",
        "            output_path = os.path.join(OUTPUT_DIR, f\"plan_{file_hash}.json\")\n",
        "            with open(output_path, 'w') as f:\n",
        "                f.write(validated_plan.model_dump_json(indent=2))\n",
        "            print(f\"‚úÖ SUCCESS! Saved validated plan to {output_path}\")\n",
        "        except ValidationError as e:\n",
        "            print(f\"‚ùå Stage 4 Failed: Pydantic validation error - {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Stage 4 Failed: An unexpected error occurred - {type(e).__name__}: {e}\")\n",
        "\n",
        "    print(\"\\nüéâ Data Factory run complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 4. (One-Time Setup) Generate Master Prompt File\n",
        "# @markdown This cell uses the `generate_prompts.py` script to create your master prompt file in Google Drive.\n",
        "# @markdown **You only need to run this cell once.**\n",
        "# @markdown Once the file is created, Cell 3 will be able to read from it for all future runs.\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Configuration ---\n",
        "#@markdown The desired location in your Google Drive for the master prompt file. This MUST match the path in Cell 3.\n",
        "DRIVE_PROMPT_FILE = \"/content/drive/MyDrive/housebrain_prompts/platinum_prompts.txt\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown The total number of prompts to generate for your master list.\n",
        "NUM_PROMPTS_TO_GENERATE = 40000 #@param {type:\"integer\"}\n",
        "# --- End Configuration ---\n",
        "\n",
        "# --- Execution ---\n",
        "# REPO_DIR is inherited from Cell 1\n",
        "script_path = os.path.join(REPO_DIR, \"scripts/generate_prompts.py\")\n",
        "\n",
        "# Ensure the repository is in the correct directory\n",
        "os.chdir(REPO_DIR)\n",
        "\n",
        "# Ensure the target directory in Drive exists\n",
        "Path(DRIVE_PROMPT_FILE).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Running prompt generation script to create {NUM_PROMPTS_TO_GENERATE} prompts...\")\n",
        "# Use an f-string for safer command construction\n",
        "command = f'python3 \"{script_path}\" --num-prompts {NUM_PROMPTS_TO_GENERATE} --output-file \"{DRIVE_PROMPT_FILE}\"'\n",
        "!{command}\n",
        "\n",
        "print(\"\\n--- Verification ---\")\n",
        "if Path(DRIVE_PROMPT_FILE).exists():\n",
        "    print(f\"‚úÖ Master prompt file successfully created at: {DRIVE_PROMPT_FILE}\")\n",
        "    print(\"First 5 prompts in the file:\")\n",
        "    !head -n 5 \"{DRIVE_PROMPT_FILE}\"\n",
        "else:\n",
        "    print(f\"‚ùå ERROR: Master prompt file was not created. Please check for errors above.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 5. (Optional) Download Generated Dataset\n",
        "# @markdown Run this cell after the data generation is complete to compress and download the entire output folder.\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "from datetime import datetime\n",
        "\n",
        "# Define the source directory in Google Drive. This should match OUTPUT_DIR from Cell 3.\n",
        "# We define it here again to make this cell self-contained.\n",
        "source_dir = \"/content/drive/MyDrive/housebrain_platinum_dataset\"\n",
        "\n",
        "# Create a timestamped zip filename\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "zip_filename = f\"housebrain_dataset_{timestamp}.zip\"\n",
        "zip_filepath = f\"/content/{zip_filename}\"\n",
        "\n",
        "if os.path.exists(source_dir) and os.listdir(source_dir):\n",
        "    # Create the zip archive\n",
        "    print(f\"Compressing '{source_dir}' into '{zip_filepath}'...\")\n",
        "    shutil.make_archive(zip_filepath.replace('.zip', ''), 'zip', source_dir)\n",
        "    print(\"‚úÖ Compression complete.\")\n",
        "\n",
        "    # Provide a download link\n",
        "    print(f\"\\nDownloading '{zip_filename}'...\")\n",
        "    files.download(zip_filepath)\n",
        "else:\n",
        "    print(f\"‚ùå ERROR: The source directory '{source_dir}' was not found or is empty. Please ensure the Data Factory ran correctly.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
