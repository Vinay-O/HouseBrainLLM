{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 1. Setup Environment\n",
        "# @markdown Mount Google Drive and clone the repository using a secure token.\n",
        "from google.colab import drive\n",
        "import os\n",
        "import getpass\n",
        "import subprocess\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"‚úÖ Google Drive mounted.\")\n",
        "\n",
        "# --- GitHub Setup ---\n",
        "#@markdown Enter your GitHub Personal Access Token (PAT) with repo access.\n",
        "GITHUB_TOKEN = getpass.getpass('Enter your GitHub PAT: ')\n",
        "REPO_URL = f\"https://{GITHUB_TOKEN}@github.com/Vinay-O/HouseBrainLLM.git\"\n",
        "REPO_DIR = \"/content/HouseBrainLLM\"\n",
        "\n",
        "# Clone the repository\n",
        "if os.path.exists(REPO_DIR):\n",
        "    print(\"Repository already exists. Pulling latest changes...\")\n",
        "    # Use subprocess.run for better error handling\n",
        "    subprocess.run(f\"cd {REPO_DIR} && git pull\", shell=True, check=True)\n",
        "else:\n",
        "    print(\"Cloning repository...\")\n",
        "    subprocess.run(f\"git clone {REPO_URL} {REPO_DIR}\", shell=True, check=True)\n",
        "\n",
        "print(\"‚úÖ Repository is ready.\")\n",
        "\n",
        "# --- Install Dependencies ---\n",
        "#@markdown Install necessary Python packages from the new requirements file.\n",
        "requirements_path = os.path.join(REPO_DIR, \"requirements.txt\")\n",
        "if os.path.exists(requirements_path):\n",
        "    print(\"Installing dependencies from requirements.txt...\")\n",
        "    !pip install -q -r {requirements_path}\n",
        "    print(\"‚úÖ Dependencies installed.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è requirements.txt not found. Installing default packages.\")\n",
        "    !pip install -q pydantic\n",
        "\n",
        "print(\"‚úÖ Environment setup complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 2. Configure and Start Ollama Server\n",
        "# @markdown This cell will download and start the Ollama server, then pull the specified model.\n",
        "# @markdown **NOTE:** A powerful model like `deepseek-r1:32b` is now recommended for higher quality results. It will be slower but more reliable.\n",
        "\n",
        "MODEL_NAME = \"deepseek-r1:32b\" # @param [\"deepseek-r1:32b\", \"llama3:70b-instruct\", \"qwen2:72b-instruct\", \"mixtral:instruct\"]\n",
        "\n",
        "# Download and start Ollama\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "import threading\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "def run_ollama():\n",
        "    try:\n",
        "        subprocess.run(\"ollama serve\", shell=True, check=True, capture_output=True, text=True)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Ollama server failed: {e.stderr}\")\n",
        "\n",
        "print(\"üöÄ Starting Ollama server in the background...\")\n",
        "ollama_thread = threading.Thread(target=run_ollama)\n",
        "ollama_thread.daemon = True\n",
        "ollama_thread.start()\n",
        "\n",
        "# Wait for the server to be ready\n",
        "print(\"‚è≥ Waiting for Ollama server to initialize...\")\n",
        "time.sleep(15) # Increased wait time for stability\n",
        "\n",
        "# Pull the model\n",
        "print(f\"üì¶ Pulling model: {MODEL_NAME}. This may take a while...\")\n",
        "try:\n",
        "    process = subprocess.run(\n",
        "        f\"ollama pull {MODEL_NAME}\",\n",
        "        shell=True, check=True, capture_output=True, text=True, timeout=900\n",
        "    )\n",
        "    print(f\"‚úÖ Model {MODEL_NAME} is ready.\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Error pulling model: {e.stderr}\")\n",
        "    print(\"This might happen if the model name is incorrect or the Ollama server is not ready.\")\n",
        "except subprocess.TimeoutExpired:\n",
        "    print(\"Timed out while pulling the model. The model might be very large or the connection slow.\")\n",
        "\n",
        "\n",
        "# Verify Ollama is running\n",
        "!ollama list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 3. Run the Data Factory\n",
        "# @markdown This cell is the core of the data generation process. It reads from the master prompt list and runs the \"Assembly Line\" process for each prompt.\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Add the cloned repo's src directory to the Python path to import the schema\n",
        "REPO_DIR = \"/content/HouseBrainLLM\"\n",
        "sys.path.append(os.path.join(REPO_DIR, 'src'))\n",
        "try:\n",
        "    from housebrain.schema import HouseOutput\n",
        "    print(\"‚úÖ Successfully imported HouseBrain schema.\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Failed to import HouseBrain schema: {e}\")\n",
        "\n",
        "import random\n",
        "import json\n",
        "import time\n",
        "import re\n",
        "from urllib.request import urlopen, Request\n",
        "from urllib.error import URLError, HTTPError\n",
        "from pydantic import ValidationError\n",
        "import hashlib\n",
        "\n",
        "# --- Configuration ---\n",
        "BATCH_SIZE = 10 # @param {type:\"integer\"}\n",
        "MASTER_PROMPT_LIST_PATH = \"/content/drive/MyDrive/housebrain_prompts/platinum_prompts.txt\" #@param {type:\"string\"}\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/housebrain_platinum_dataset\" # @param {type:\"string\"}\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "def generate_file_hash(prompt_text):\n",
        "    \"\"\"Creates a unique and consistent hash for a given prompt text.\"\"\"\n",
        "    return hashlib.sha256(prompt_text.encode('utf-8')).hexdigest()[:16]\n",
        "\n",
        "# --- Prompts ---\n",
        "# ... (rest of the cell is the same)\n",
        "\n",
        "# --- Prompts ---\n",
        "\n",
        "STAGE_1_LAYOUT_PROMPT = \"\"\"\n",
        "You are an expert architectural AI. Your task is to generate the foundational layout for a house based on a user's prompt.\n",
        "\n",
        "**Instructions:**\n",
        "1.  **Analyze the Request:** Carefully read the user's prompt to understand the constraints (e.g., plot size, number of floors, total area, number of rooms).\n",
        "2.  **Design the Layout:** Create a logical and functional floor plan. Ensure rooms are reasonably sized and placed.\n",
        "3.  **Define Levels and Rooms:** Structure your output with levels (e.g., ground floor, first floor) and the rooms within each level.\n",
        "4.  **Specify Room Bounds:** For each room, define its `bounds` as a rectangle with `x`, `y`, `width`, and `height`. The origin (0,0) is the top-left corner of the plot.\n",
        "5.  **Adhere to the Schema:** The output MUST be a single JSON object that validates against the `HouseOutput` schema, but **ONLY include the `levels` and `rooms`**. Do NOT include `doors` or `windows` at this stage.\n",
        "6.  **Use Unique IDs:** Assign a unique string `id` to every level and every room (e.g., \"level_0\", \"room_0\", \"kitchen_0\").\n",
        "\n",
        "**User Prompt:**\n",
        "{user_prompt}\n",
        "\n",
        "**Output Format (JSON Object only):**\n",
        "```json\n",
        "{{\n",
        "  \"levels\": [\n",
        "    {{\n",
        "      \"id\": \"level_0\",\n",
        "      \"level_number\": 0,\n",
        "      \"rooms\": [\n",
        "        {{\n",
        "          \"id\": \"living_room_0\",\n",
        "          \"room_type\": \"living_room\",\n",
        "          \"bounds\": {{\"x\": 0, \"y\": 0, \"width\": 20, \"height\": 15}}\n",
        "        }},\n",
        "        {{\n",
        "          \"id\": \"kitchen_0\",\n",
        "          \"room_type\": \"kitchen\",\n",
        "          \"bounds\": {{\"x\": 20, \"y\": 0, \"width\": 10, \"height\": 15}}\n",
        "        }}\n",
        "      ]\n",
        "    }}\n",
        "  ]\n",
        "}}\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "STAGE_2_DOORS_PROMPT = \"\"\"\n",
        "You are an expert architectural AI. You will be given a JSON object describing a house layout. Your task is to add doors to this layout.\n",
        "\n",
        "**Instructions:**\n",
        "1.  **Analyze the Layout:** Review the provided `levels` and `rooms` JSON. Understand the room adjacencies.\n",
        "2.  **Place Doors:** Add doors logically. Every room should be accessible. Add an exterior door for the main entrance. Connect adjacent rooms where appropriate.\n",
        "3.  **Define Door Properties:** For each door, specify its `position` (`x`, `y`), `width`, `type` ('interior', 'exterior', 'sliding', 'pocket'), and the two room IDs it connects (`room1`, `room2`). For exterior doors, `room2` should be a descriptive string like \"exterior_front\" or \"exterior_backyard\".\n",
        "4.  **Adhere to the Schema:** The output MUST be a single JSON list of `Door` objects. Do NOT include any other text, conversation, or markdown.\n",
        "\n",
        "**House Layout:**\n",
        "{layout_json}\n",
        "\n",
        "**Golden Example:**\n",
        "A door connecting `living_room_0` and `kitchen_0` might look like this:\n",
        "`{{ \"position\": {{\"x\": 19.5, \"y\": 7}}, \"width\": 3, \"type\": \"interior\", \"room1\": \"living_room_0\", \"room2\": \"kitchen_0\" }}`\n",
        "\n",
        "**Output Format (JSON List only):**\n",
        "```json\n",
        "[\n",
        "  {{\n",
        "    \"position\": {{\"x\": 0, \"y\": 7}},\n",
        "    \"width\": 3.5,\n",
        "    \"type\": \"exterior\",\n",
        "    \"room1\": \"entrance_0\",\n",
        "    \"room2\": \"exterior_front\"\n",
        "  }},\n",
        "  {{\n",
        "    \"position\": {{\"x\": 10, \"y\": 7}},\n",
        "    \"width\": 3,\n",
        "    \"type\": \"interior\",\n",
        "    \"room1\": \"entrance_0\",\n",
        "    \"room2\": \"living_room_0\"\n",
        "  }}\n",
        "]\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "STAGE_3_WINDOWS_PROMPT = \"\"\"\n",
        "You are an expert architectural AI. You will be given a JSON object describing a house layout. Your task is to add windows to this layout.\n",
        "\n",
        "**Instructions:**\n",
        "1.  **Analyze the Layout:** Review the provided `levels` and `rooms` JSON.\n",
        "2.  **Place Windows:** Add windows logically to exterior walls. Rooms like living rooms and bedrooms should have ample windows. Bathrooms might have smaller or fewer windows.\n",
        "3.  **Define Window Properties:** For each window, specify its `position` (`x`, `y`), `width`, `height`, `type` ('fixed', 'casement', 'sliding', 'bay'), and the `room_id` it belongs to.\n",
        "4.  **Adhere to the Schema:** The output MUST be a single JSON list of `Window` objects. Do NOT include any other text, conversation, or markdown.\n",
        "\n",
        "**House Layout:**\n",
        "{layout_json}\n",
        "\n",
        "**Output Format (JSON List only):**\n",
        "```json\n",
        "[\n",
        "  {{\n",
        "    \"position\": {{\"x\": 5, \"y\": 0}},\n",
        "    \"width\": 8,\n",
        "    \"height\": 5,\n",
        "    \"type\": \"bay\",\n",
        "    \"room_id\": \"living_room_0\"\n",
        "  }},\n",
        "  {{\n",
        "    \"position\": {{\"x\": 25, \"y\": 0}},\n",
        "    \"width\": 4,\n",
        "    \"height\": 3,\n",
        "    \"type\": \"sliding\",\n",
        "    \"room_id\": \"kitchen_0\"\n",
        "  }}\n",
        "]\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def call_ollama_colab(model, prompt, max_retries=3, delay=5):\n",
        "    \"\"\"Function to call the Ollama API running on Google Colab.\"\"\"\n",
        "    OLLAMA_ENDPOINT = \"http://localhost:11434/api/generate\"\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    data = {\"model\": model, \"prompt\": prompt, \"stream\": False}\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            req = Request(OLLAMA_ENDPOINT, data=json.dumps(data).encode(\"utf-8\"), headers=headers, method=\"POST\")\n",
        "            with urlopen(req) as response:\n",
        "                response_body = response.read().decode(\"utf-8\")\n",
        "                response_json = json.loads(response_body)\n",
        "                return response_json.get(\"response\", \"\").strip()\n",
        "        except (URLError, HTTPError, ConnectionResetError) as e:\n",
        "            print(f\"ERROR: Ollama connection error on attempt {attempt + 1}/{max_retries}: {e}\")\n",
        "            if attempt < max_retries - 1:\n",
        "                print(f\"Retrying in {delay} seconds...\")\n",
        "                time.sleep(delay)\n",
        "            else:\n",
        "                print(\"ERROR: Max retries reached. Failing.\")\n",
        "                return None\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR: Unexpected error calling Ollama: {e}\")\n",
        "            return None\n",
        "\n",
        "def repair_json(text, target_type=dict):\n",
        "    \"\"\"\n",
        "    Aggressively finds and parses a JSON object or list from a string.\n",
        "    Even if it's embedded in conversation or markdown.\n",
        "    \"\"\"\n",
        "    text = str(text) # Ensure input is a string\n",
        "\n",
        "    # Determine the start and end delimiters based on the target type\n",
        "    if target_type == list:\n",
        "        start_char, end_char = '[', ']'\n",
        "    else:\n",
        "        start_char, end_char = '{', '}'\n",
        "\n",
        "    # 1. First, try a direct parse. This is the ideal case.\n",
        "    try:\n",
        "        parsed = json.loads(text)\n",
        "        if isinstance(parsed, target_type):\n",
        "            print(\"‚úÖ Initial parse successful.\")\n",
        "            return parsed\n",
        "    except json.JSONDecodeError:\n",
        "        pass # It's not a clean JSON, so we move to extraction\n",
        "\n",
        "    # 2. If direct parse fails, use regex to find the JSON blob.\n",
        "    # This regex is designed to find the first occurrence of a valid JSON structure.\n",
        "    print(f\"Initial parse for type {target_type.__name__} failed. Attempting aggressive extraction...\")\n",
        "    pattern = re.compile(f'\\\\{start_char}[\\\\s\\\\S]*\\\\{end_char}')\n",
        "    match = pattern.search(text)\n",
        "\n",
        "    if not match:\n",
        "        print(f\"‚ùå No JSON structure of type {target_type.__name__} found in the text.\")\n",
        "        return None\n",
        "\n",
        "    potential_json = match.group(0)\n",
        "    try:\n",
        "        parsed = json.loads(potential_json)\n",
        "        if isinstance(parsed, target_type):\n",
        "            print(f\"‚úÖ Successfully extracted and parsed JSON of type {target_type.__name__}.\")\n",
        "            return parsed\n",
        "        else:\n",
        "            # Fallback for when a list is wrapped in a dict\n",
        "            if target_type == list and isinstance(parsed, dict):\n",
        "                for key, value in parsed.items():\n",
        "                    if isinstance(value, list):\n",
        "                        print(f\"‚úÖ Repaired JSON by extracting list from key '{key}'.\")\n",
        "                        return value\n",
        "            print(f\"‚ùå Extracted JSON is not of the target type {target_type.__name__}.\")\n",
        "            return None\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"‚ùå Failed to parse the extracted JSON blob: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def assemble_plan(layout_dict, doors_list, windows_list):\n",
        "    \"\"\"A completely bulletproof assembly function that can handle any malformed data.\"\"\"\n",
        "    # Safety wrapper for dict access to handle any possible type error\n",
        "    def safe_get(d, key, default=None):\n",
        "        try:\n",
        "            if not isinstance(d, dict):\n",
        "                return default\n",
        "            return d.get(key, default)\n",
        "        except:\n",
        "            return default\n",
        "\n",
        "    # Initialize an empty result with a safe structure\n",
        "    result = {\"levels\": []}\n",
        "\n",
        "    # Safely extract and verify the levels\n",
        "    try:\n",
        "        if not isinstance(layout_dict, dict):\n",
        "            print(\"‚ö†Ô∏è Assembly Error: Layout is not a dictionary. Creating empty layout.\")\n",
        "            return result\n",
        "\n",
        "        levels = safe_get(layout_dict, \"levels\", [])\n",
        "        if not isinstance(levels, list):\n",
        "            print(\"‚ö†Ô∏è Assembly Error: 'levels' key is not a list. Creating empty layout.\")\n",
        "            return result\n",
        "\n",
        "        result[\"levels\"] = levels\n",
        "\n",
        "        # Create a safe room lookup dictionary\n",
        "        rooms_by_id = {}\n",
        "\n",
        "        # Process each level and room with complete safety\n",
        "        for level_idx, level in enumerate(levels):\n",
        "            try:\n",
        "                if not isinstance(level, dict):\n",
        "                    print(f\"‚ö†Ô∏è Assembly Warning: Skipping non-dict level at index {level_idx}.\")\n",
        "                    continue\n",
        "\n",
        "                # Initialize an empty rooms list if needed\n",
        "                if \"rooms\" not in level or not isinstance(level[\"rooms\"], list):\n",
        "                    level[\"rooms\"] = []\n",
        "                    continue\n",
        "\n",
        "                # Process each room\n",
        "                for room_idx, room in enumerate(level[\"rooms\"]):\n",
        "                    try:\n",
        "                        if not isinstance(room, dict):\n",
        "                            print(f\"‚ö†Ô∏è Assembly Warning: Skipping non-dict room at index {room_idx}.\")\n",
        "                            continue\n",
        "\n",
        "                        room_id = safe_get(room, \"id\")\n",
        "                        if not isinstance(room_id, str):\n",
        "                            print(f\"‚ö†Ô∏è Assembly Warning: Room has invalid ID: {room_id}\")\n",
        "                            continue\n",
        "\n",
        "                        # Initialize empty collections for doors and windows\n",
        "                        if \"doors\" not in room or not isinstance(room[\"doors\"], list):\n",
        "                            room[\"doors\"] = []\n",
        "                        if \"windows\" not in room or not isinstance(room[\"windows\"], list):\n",
        "                            room[\"windows\"] = []\n",
        "\n",
        "                        # Add to lookup\n",
        "                        rooms_by_id[room_id] = room\n",
        "                    except Exception as e:\n",
        "                        print(f\"‚ö†Ô∏è Assembly Warning: Error processing room: {str(e)}\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Assembly Warning: Error processing level: {str(e)}\")\n",
        "\n",
        "        # Process windows safely\n",
        "        if isinstance(windows_list, list):\n",
        "            for window_idx, window in enumerate(windows_list):\n",
        "                try:\n",
        "                    if not isinstance(window, dict):\n",
        "                        print(f\"‚ö†Ô∏è Assembly Warning: Discarding non-dict window at index {window_idx}: {window}\")\n",
        "                        continue\n",
        "\n",
        "                    room_id = safe_get(window, \"room_id\")\n",
        "                    if not isinstance(room_id, str) or room_id not in rooms_by_id:\n",
        "                        print(f\"‚ö†Ô∏è Assembly Warning: Window has invalid room_id: {room_id}\")\n",
        "                        continue\n",
        "\n",
        "                    # Verify window has required fields\n",
        "                    required_fields = [\"position\", \"width\", \"height\", \"type\"]\n",
        "                    for field in required_fields:\n",
        "                        if field not in window:\n",
        "                            print(f\"‚ö†Ô∏è Assembly Warning: Window missing required field: {field}\")\n",
        "                            break\n",
        "                    else:\n",
        "                        # All checks passed, safe to add\n",
        "                        rooms_by_id[room_id][\"windows\"].append(window)\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è Assembly Warning: Error processing window: {str(e)}\")\n",
        "\n",
        "        # Process doors safely\n",
        "        if isinstance(doors_list, list):\n",
        "            for door_idx, door in enumerate(doors_list):\n",
        "                try:\n",
        "                    if not isinstance(door, dict):\n",
        "                        print(f\"‚ö†Ô∏è Assembly Warning: Discarding non-dict door at index {door_idx}: {door}\")\n",
        "                        continue\n",
        "\n",
        "                    room1_id = safe_get(door, \"room1\")\n",
        "                    if not isinstance(room1_id, str) or room1_id not in rooms_by_id:\n",
        "                        print(f\"‚ö†Ô∏è Assembly Warning: Door has invalid room1_id: {room1_id}\")\n",
        "                        continue\n",
        "\n",
        "                    # Verify door has required fields\n",
        "                    required_fields = [\"position\", \"width\", \"type\", \"room2\"]\n",
        "                    for field in required_fields:\n",
        "                        if field not in door:\n",
        "                            print(f\"‚ö†Ô∏è Assembly Warning: Door missing required field: {field}\")\n",
        "                            break\n",
        "                    else:\n",
        "                        # All checks passed, safe to add\n",
        "                        rooms_by_id[room1_id][\"doors\"].append(door)\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è Assembly Warning: Error processing door: {str(e)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Assembly Error: Unexpected error during assembly: {str(e)}\")\n",
        "\n",
        "    return result\n",
        "\n",
        "# --- Execution ---\n",
        "\n",
        "print(\"--- Starting Data Factory Run (V3: Assembly Line) ---\")\n",
        "\n",
        "# Load the master list of prompts\n",
        "with open(MASTER_PROMPT_LIST_PATH, 'r') as f:\n",
        "    master_prompt_list = f.read().splitlines()\n",
        "print(f\"‚úÖ Found {len(master_prompt_list)} total prompts in the master list.\")\n",
        "\n",
        "\n",
        "# In parallel mode, we process a small, random batch of prompts\n",
        "prompts_to_process = random.sample(master_prompt_list, BATCH_SIZE)\n",
        "print(f\"‚úÖ This run will process a random batch of {len(prompts_to_process)} prompts.\")\n",
        "\n",
        "\n",
        "for i, prompt_text in enumerate(prompts_to_process):\n",
        "    print(\"\\n==================================================\")\n",
        "    print(f\"Processing prompt {i+1}/{len(prompts_to_process)}\")\n",
        "    # Truncate for display\n",
        "    print(prompt_text[:100] + \"...\" if len(prompt_text) > 100 else prompt_text)\n",
        "    print(\"==================================================\")\n",
        "\n",
        "    # --- STAGE 1: Layout ---\n",
        "    print(\"Running Stage 1: Layout Generation...\")\n",
        "    stage_1_prompt = STAGE_1_LAYOUT_PROMPT.format(user_prompt=prompt_text)\n",
        "    stage_1_response_text = call_ollama_colab(MODEL_NAME, stage_1_prompt)\n",
        "    if not stage_1_response_text:\n",
        "        print(\"‚ùå Stage 1 Failed: No response from model.\")\n",
        "        continue\n",
        "    layout_data = repair_json(stage_1_response_text, target_type=dict)\n",
        "    if not layout_data:\n",
        "        print(\"‚ùå Stage 1 Failed: Could not produce a valid layout JSON.\")\n",
        "        continue\n",
        "\n",
        "    # --- STAGE 2: Doors ---\n",
        "    print(\"Running Stage 2: Door Generation...\")\n",
        "    layout_json_str = json.dumps(layout_data, indent=2)\n",
        "    stage_2_prompt = STAGE_2_DOORS_PROMPT.format(layout_json=layout_json_str)\n",
        "    stage_2_response_text = call_ollama_colab(MODEL_NAME, stage_2_prompt)\n",
        "    if not stage_2_response_text:\n",
        "        print(\"‚ùå Stage 2 Failed: No response from model.\")\n",
        "        continue\n",
        "    doors_data = repair_json(stage_2_response_text, target_type=list)\n",
        "    if doors_data is None: # Check for None specifically, as [] is a valid list\n",
        "        print(\"‚ùå Stage 2 Failed: Could not produce a valid list of doors.\")\n",
        "        continue\n",
        "\n",
        "    # --- STAGE 3: Windows ---\n",
        "    print(\"Running Stage 3: Window Generation...\")\n",
        "    stage_3_prompt = STAGE_3_WINDOWS_PROMPT.format(layout_json=layout_json_str)\n",
        "    stage_3_response_text = call_ollama_colab(MODEL_NAME, stage_3_prompt)\n",
        "    if not stage_3_response_text:\n",
        "        print(\"‚ùå Stage 3 Failed: No response from model.\")\n",
        "        continue\n",
        "    windows_data = repair_json(stage_3_response_text, target_type=list)\n",
        "    if windows_data is None: # Check for None specifically, as [] is a valid list\n",
        "        print(\"‚ùå Stage 3 Failed: Could not produce a valid list of windows.\")\n",
        "        continue\n",
        "\n",
        "    # --- STAGE 4: Assembly & Validation ---\n",
        "    print(\"Running Stage 4: Assembling and Validating...\")\n",
        "    try:\n",
        "        # Assemble the plan using the new bulletproof function\n",
        "        final_plan_dict = assemble_plan(layout_data, doors_data, windows_data)\n",
        "\n",
        "        # Inject metadata\n",
        "        final_plan_dict['basicDetails'] = {\n",
        "            'prompt': prompt_text\n",
        "        }\n",
        "\n",
        "        # Validate with Pydantic\n",
        "        validated_plan = HouseOutput.model_validate(final_plan_dict)\n",
        "\n",
        "        # Save the validated plan\n",
        "        file_hash = generate_file_hash(prompt_text)\n",
        "        output_path = os.path.join(OUTPUT_DIR, f\"plan_{file_hash}.json\")\n",
        "        with open(output_path, 'w') as f:\n",
        "            f.write(validated_plan.model_dump_json(indent=2))\n",
        "        print(f\"‚úÖ SUCCESS! Saved validated plan to {output_path}\")\n",
        "\n",
        "    except ValidationError as e:\n",
        "        print(f\"‚ùå Stage 4 Failed: Pydantic validation error - {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Stage 4 Failed: An unexpected error occurred - {e}\")\n",
        "\n",
        "\n",
        "print(\"\\nüéâ Data Factory run complete!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 4. (One-Time Setup) Generate Master Prompt File\n",
        "# @markdown This cell uses the `generate_prompts.py` script to create your master prompt file in Google Drive.\n",
        "# @markdown **You only need to run this cell once.**\n",
        "# @markdown Once the file is created, Cell 3 will be able to read from it for all future runs.\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Configuration ---\n",
        "#@markdown The desired location in your Google Drive for the master prompt file. This MUST match the path in Cell 3.\n",
        "DRIVE_PROMPT_FILE = \"/content/drive/MyDrive/housebrain_prompts/platinum_prompts.txt\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown The total number of prompts to generate for your master list.\n",
        "NUM_PROMPTS_TO_GENERATE = 40000 #@param {type:\"integer\"}\n",
        "# --- End Configuration ---\n",
        "\n",
        "# --- Execution ---\n",
        "REPO_DIR = \"/content/HouseBrainLLM\"\n",
        "script_path = os.path.join(REPO_DIR, \"scripts/generate_prompts.py\")\n",
        "\n",
        "# Ensure the repository is in the correct directory\n",
        "os.chdir(REPO_DIR)\n",
        "\n",
        "# Ensure the target directory in Drive exists\n",
        "Path(DRIVE_PROMPT_FILE).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Running prompt generation script to create {NUM_PROMPTS_TO_GENERATE} prompts...\")\n",
        "# Use an f-string for safer command construction\n",
        "command = f'python3 \"{script_path}\" --num-prompts {NUM_PROMPTS_TO_GENERATE} --output-file \"{DRIVE_PROMPT_FILE}\"'\n",
        "!{command}\n",
        "\n",
        "print(\"\\n--- Verification ---\")\n",
        "if Path(DRIVE_PROMPT_FILE).exists():\n",
        "    print(f\"‚úÖ Master prompt file successfully created at: {DRIVE_PROMPT_FILE}\")\n",
        "    print(\"First 5 prompts in the file:\")\n",
        "    !head -n 5 \"{DRIVE_PROMPT_FILE}\"\n",
        "else:\n",
        "    print(f\"‚ùå ERROR: Master prompt file was not created. Please check for errors above.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 5. (Optional) Download Generated Dataset\n",
        "# @markdown Run this cell after the data generation is complete to compress and download the entire output folder.\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "from datetime import datetime\n",
        "\n",
        "# Define the source directory in Google Drive. This should match DRIVE_OUTPUT_DIR from Cell 3.\n",
        "source_dir = \"/content/drive/MyDrive/housebrain_platinum_dataset\"\n",
        "\n",
        "# Create a timestamped zip filename\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "zip_filename = f\"housebrain_dataset_{timestamp}.zip\"\n",
        "zip_filepath = f\"/content/{zip_filename}\"\n",
        "\n",
        "if os.path.exists(source_dir) and os.listdir(source_dir):\n",
        "    # Create the zip archive\n",
        "    print(f\"Compressing '{source_dir}' into '{zip_filepath}'...\")\n",
        "    shutil.make_archive(zip_filepath.replace('.zip', ''), 'zip', source_dir)\n",
        "    print(\"‚úÖ Compression complete.\")\n",
        "\n",
        "    # Provide a download link\n",
        "    print(f\"\\nDownloading '{zip_filename}'...\")\n",
        "    files.download(zip_filepath)\n",
        "else:\n",
        "    print(f\"‚ùå ERROR: The source directory '{source_dir}' was not found or is empty. Please ensure the Data Factory ran correctly.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
