{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HouseBrain Data Factory 2.0: The Architect's Assembly Line (Parallel Mode)\n",
        "\n",
        "This notebook is the control center for generating a high-quality, architecturally-sound dataset for training the HouseBrain LLM. It is designed for **large-scale, parallel data generation.**\n",
        "\n",
        "**Our Strategy:**\n",
        "1.  **Generate a Master Prompt File (Once)**: Run Cell 4 a single time to generate a large (e.g., 30,000) list of prompts and save it to your Google Drive.\n",
        "2.  **Run Multiple Notebooks in Parallel**: You can open this same notebook using different Google accounts.\n",
        "3.  **Process Random Batches**: Each notebook instance will read from the master prompt list, select a random, unique batch of prompts to process, and save the results to a central dataset folder on your Drive.\n",
        "4.  **Avoid Duplicate Work**: The script checks if a plan for a given prompt already exists, allowing multiple instances to contribute to the same dataset without collisions.\n",
        "\n",
        "## Instructions\n",
        "1.  **Set Your GitHub PAT**: In Cell 1, you will be prompted to enter a GitHub Personal Access Token to clone the repository.\n",
        "2.  **(First Time Only) Run Cell 4**: Run Cell 4 to create your master `platinum_prompts.txt` file in Google Drive. You only need to do this once.\n",
        "3.  **Run the Factory (Cell 3)**: Run cells 1, 2, and 3. You can configure the number of plans you want the current notebook instance to generate in Cell 3.\n",
        "4.  **Repeat**: Open this notebook with other accounts, mount the same Google Drive, and run Cell 3 again to generate more data in parallel.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 1. Setup Environment\n",
        "# @markdown Mount Google Drive and clone the repository using a secure token.\n",
        "from google.colab import drive\n",
        "import os\n",
        "import getpass\n",
        "import subprocess\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"‚úÖ Google Drive mounted.\")\n",
        "\n",
        "# --- GitHub Setup ---\n",
        "#@markdown Enter your GitHub Personal Access Token (PAT) with repo access.\n",
        "GITHUB_TOKEN = getpass.getpass('Enter your GitHub PAT: ')\n",
        "REPO_URL = f\"https://{GITHUB_TOKEN}@github.com/Vinay-O/HouseBrainLLM.git\"\n",
        "REPO_DIR = \"/content/HouseBrainLLM\"\n",
        "\n",
        "# Clone the repository\n",
        "if os.path.exists(REPO_DIR):\n",
        "    print(\"Repository already exists. Pulling latest changes...\")\n",
        "    # Use subprocess.run for better error handling\n",
        "    subprocess.run(f\"cd {REPO_DIR} && git pull\", shell=True, check=True)\n",
        "else:\n",
        "    print(\"Cloning repository...\")\n",
        "    subprocess.run(f\"git clone {REPO_URL} {REPO_DIR}\", shell=True, check=True)\n",
        "\n",
        "print(\"‚úÖ Repository is ready.\")\n",
        "\n",
        "# --- Install Dependencies ---\n",
        "#@markdown Install necessary Python packages from the new requirements file.\n",
        "requirements_path = os.path.join(REPO_DIR, \"requirements.txt\")\n",
        "if os.path.exists(requirements_path):\n",
        "    print(\"Installing dependencies from requirements.txt...\")\n",
        "    !pip install -q -r {requirements_path}\n",
        "    print(\"‚úÖ Dependencies installed.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è requirements.txt not found. Installing default packages.\")\n",
        "    !pip install -q pydantic\n",
        "\n",
        "print(\"‚úÖ Environment setup complete.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 2. Configure and Start Ollama Server\n",
        "# @markdown This cell will download and start the Ollama server, then pull the specified model.\n",
        "# @markdown **NOTE:** A powerful model like `deepseek-r1:32b` is now recommended for higher quality results. It will be slower but more reliable.\n",
        "\n",
        "MODEL_NAME = \"deepseek-r1:32b\" # @param [\"deepseek-r1:32b\", \"llama3:70b-instruct\", \"qwen2:72b-instruct\", \"mixtral:instruct\"]\n",
        "\n",
        "# Download and start Ollama\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "import threading\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "def run_ollama():\n",
        "    try:\n",
        "        subprocess.run(\"ollama serve\", shell=True, check=True, capture_output=True, text=True)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Ollama server failed: {e.stderr}\")\n",
        "\n",
        "print(\"üöÄ Starting Ollama server in the background...\")\n",
        "ollama_thread = threading.Thread(target=run_ollama)\n",
        "ollama_thread.daemon = True\n",
        "ollama_thread.start()\n",
        "\n",
        "# Wait for the server to be ready\n",
        "print(\"‚è≥ Waiting for Ollama server to initialize...\")\n",
        "time.sleep(15) # Increased wait time for stability\n",
        "\n",
        "# Pull the model\n",
        "print(f\"üì¶ Pulling model: {MODEL_NAME}. This may take a while...\")\n",
        "try:\n",
        "    process = subprocess.run(\n",
        "        f\"ollama pull {MODEL_NAME}\",\n",
        "        shell=True, check=True, capture_output=True, text=True, timeout=900\n",
        "    )\n",
        "    print(f\"‚úÖ Model {MODEL_NAME} is ready.\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Error pulling model: {e.stderr}\")\n",
        "    print(\"This might happen if the model name is incorrect or the Ollama server is not ready.\")\n",
        "except subprocess.TimeoutExpired:\n",
        "    print(\"Timed out while pulling the model. The model might be very large or the connection slow.\")\n",
        "\n",
        "\n",
        "# Verify Ollama is running\n",
        "!ollama list\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 3. Run the Data Factory (Parallel Mode)\n",
        "# @markdown This cell is designed for large-scale, parallel data generation.\n",
        "# @markdown It reads prompts from a central file in your Google Drive, processes a random batch, and saves to a central dataset folder.\n",
        "# @markdown You can run this notebook on multiple accounts simultaneously to accelerate data creation.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import textwrap\n",
        "import logging\n",
        "from pathlib import Path\n",
        "import urllib.request\n",
        "import urllib.error\n",
        "from inspect import getsource\n",
        "from pydantic import BaseModel, ValidationError\n",
        "import random\n",
        "import hashlib\n",
        "import time\n",
        "\n",
        "# --- Configuration ---\n",
        "#@markdown The central location in your Google Drive for the master prompt file.\n",
        "DRIVE_PROMPT_FILE = \"/content/drive/MyDrive/housebrain_prompts/platinum_prompts.txt\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown The central location in your Google Drive to save the final dataset.\n",
        "DRIVE_OUTPUT_DIR = \"/content/drive/MyDrive/housebrain_platinum_dataset\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown The number of plans this specific Colab instance should generate in this run.\n",
        "NUM_PLANS_TO_GENERATE = 100 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown The Ollama model to use for generation (should match the model from Cell 2).\n",
        "MODEL_NAME = \"deepseek-r1:32b\" # @param [\"deepseek-r1:32b\", \"llama3:70b-instruct\", \"qwen2:72b-instruct\", \"mixtral:instruct\"]\n",
        "# --- End Configuration ---\n",
        "\n",
        "\n",
        "# --- Setup Paths and Logging ---\n",
        "REPO_DIR = \"/content/HouseBrainLLM\"\n",
        "if REPO_DIR not in sys.path:\n",
        "    sys.path.insert(0, REPO_DIR)\n",
        "os.chdir(REPO_DIR)\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# --- Import Schema from Cloned Repo ---\n",
        "try:\n",
        "    from src.housebrain.schema import HouseOutput, RoomType\n",
        "    print(\"‚úÖ Successfully imported HouseBrain schema.\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Failed to import HouseBrain schema: {e}\")\n",
        "    print(\"Please ensure the repository was cloned correctly in Step 1.\")\n",
        "    # Stop execution if schema fails\n",
        "    raise e\n",
        "\n",
        "# --- Self-Contained Generation Logic (with A+ Prompts) ---\n",
        "VALID_ROOM_TYPES = [e.value for e in RoomType]\n",
        "VALID_WINDOW_TYPES = [\"fixed\", \"casement\", \"sliding\", \"bay\"]\n",
        "VALID_DOOR_TYPES = [\"interior\", \"exterior\", \"sliding\", \"pocket\"]\n",
        "\n",
        "STAGE_1_PROMPT_TEMPLATE = \"\"\"You are an expert AI architect. Your task is to generate ONLY the high-level geometric layout for a house based on a user's prompt.\n",
        "\n",
        "**CRITICAL INSTRUCTIONS:**\n",
        "1.  Focus ONLY on `levels` and `rooms`.\n",
        "2.  Rooms MUST have an `id`, `type`, and non-overlapping `bounds`. **BOUNDS MUST NOT OVERLAP.**\n",
        "3.  The `type` for each room MUST be one of the following valid options: `{valid_room_types}`. Do NOT invent new types or use shorthands.\n",
        "4.  **Size Constraint**: Rooms must have realistic dimensions. For example, an `entrance` must be at least 40 sqft, a `bathroom` at least 40 sqft, and a `bedroom` at least 120 sqft.\n",
        "5.  DO NOT include `doors` or `windows` in this stage.\n",
        "6.  Your output MUST be a single, valid JSON object with a root \"levels\" key.\n",
        "\n",
        "**Golden Example of a perfect room structure:**\n",
        "```json\n",
        "{{\n",
        "  \"id\": \"living_room_0\",\n",
        "  \"type\": \"living_room\",\n",
        "  \"bounds\": {{\"x\": 10, \"y\": 10, \"width\": 20, \"height\": 15}}\n",
        "}}\n",
        "```\n",
        "---\n",
        "**User Prompt:**\n",
        "{user_prompt}\n",
        "---\n",
        "Now, generate the JSON for the house layout, adhering strictly to the instructions provided.\"\"\"\n",
        "\n",
        "STAGE_2_PROMPT_TEMPLATE = \"\"\"You are an expert AI architect. Your task is to add `doors` and `windows` to a pre-existing house layout.\n",
        "\n",
        "**CRITICAL INSTRUCTIONS:**\n",
        "1.  Use ONLY the official `RoomType` enum values for all room `type` fields. Valid types are: `{valid_room_types}`. Do not use shorthands like \"living\".\n",
        "2.  The `type` for each window MUST be one of the following valid options: `{valid_window_types}`.\n",
        "3.  The `type` for each door MUST be one of the following valid options: `{valid_door_types}`. Do NOT confuse window and door types.\n",
        "4.  DO NOT change the existing `id`, `type`, or `bounds` of the rooms.\n",
        "5.  A `Door` object MUST have `room1` and `room2` fields (NOT `room1_id`). A `Window` MUST have a `room_id`.\n",
        "6.  Your final output must be a single JSON object containing ONLY the `levels` key.\n",
        "\n",
        "**Expert Design Hints:**\n",
        "-   Place doors to create a logical and efficient flow between connected rooms.\n",
        "-   Place windows on exterior walls to maximize natural light and capture views where appropriate.\n",
        "\n",
        "**Golden Example (Pay close attention to structure):**\n",
        "```json\n",
        "\"rooms\": [\n",
        "   {{\n",
        "     \"id\": \"living_room_0\",\n",
        "     \"type\": \"living_room\",\n",
        "     \"bounds\": {{ \"x\": 10, \"y\": 10, \"width\": 20, \"height\": 15 }},\n",
        "     \"doors\": [\n",
        "       {{\n",
        "         \"position\": {{ \"x\": 20, \"y\": 25 }},\n",
        "         \"width\": 3.0,\n",
        "         \"type\": \"interior\",\n",
        "         \"room1\": \"living_room_0\",\n",
        "         \"room2\": \"dining_room_0\"\n",
        "       }}\n",
        "     ],\n",
        "     \"windows\": [ {{ \"position\": {{...}}, \"width\": 8.0, \"height\": 5.0, \"type\": \"sliding\", \"room_id\": \"living_room_0\" }} ]\n",
        "   }}\n",
        "]\n",
        "```\n",
        "---\n",
        "**Existing House Layout (Do not change this part):**\n",
        "```json\n",
        "{existing_layout}\n",
        "```\n",
        "---\n",
        "**Original User Prompt:**\n",
        "{user_prompt}\n",
        "---\n",
        "Now, add the doors and windows to the layout, following the format of the Golden Example and Schema Reference exactly.\"\"\"\n",
        "\n",
        "JSON_REPAIR_PROMPT = \"\"\"The following text is not a valid JSON object. Please fix any syntax errors (like missing commas, brackets, or quotes) and return ONLY the corrected, valid JSON object. Do not add any commentary.\n",
        "\n",
        "**Broken Text:**\n",
        "{broken_json}\n",
        "\"\"\"\n",
        "\n",
        "def call_ollama_colab(model_name: str, prompt: str, max_retries=3):\n",
        "    \"\"\"A more robust implementation of the Ollama API call for Colab with retries.\"\"\"\n",
        "    url = \"http://localhost:11434/api/generate\"\n",
        "    data = {\"model\": model_name, \"prompt\": prompt, \"stream\": False, \"format\": \"json\"}\n",
        "    encoded_data = json.dumps(data).encode('utf-8')\n",
        "    req = urllib.request.Request(url, data=encoded_data, headers={'Content-Type': 'application/json'})\n",
        "    \n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            with urllib.request.urlopen(req, timeout=900) as response:\n",
        "                if response.status == 200:\n",
        "                    response_data = json.loads(response.read().decode('utf-8'))\n",
        "                    return response_data.get(\"response\", \"\")\n",
        "        except urllib.error.HTTPError as e:\n",
        "            error_content = e.read().decode('utf-8')\n",
        "            logger.error(f\"HTTP Error: {e.code} {e.reason} - {error_content}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Attempt {attempt + 1}/{max_retries} failed. Error calling Ollama: {e}\")\n",
        "            if attempt < max_retries - 1:\n",
        "                time.sleep(5)\n",
        "            else:\n",
        "                logger.error(\"Max retries reached. Failing.\")\n",
        "    return None\n",
        "\n",
        "def repair_and_correct_plan(raw_json_str: str, model_name: str) -> dict:\n",
        "    \"\"\"Attempts to parse, repair, and programmatically correct a JSON plan.\"\"\"\n",
        "    plan_dict = None\n",
        "    # --- Step 1: Initial Parse Attempt ---\n",
        "    try:\n",
        "        plan_dict = json.loads(raw_json_str)\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"Initial JSON parse failed. Attempting to repair with LLM...\")\n",
        "        repair_prompt = JSON_REPAIR_PROMPT.format(broken_json=raw_json_str)\n",
        "        repaired_str = call_ollama_colab(model_name, repair_prompt)\n",
        "        if not repaired_str:\n",
        "            print(\"‚ùå JSON repair failed.\")\n",
        "            return None\n",
        "        try:\n",
        "            plan_dict = json.loads(repaired_str)\n",
        "            print(\"‚úÖ JSON successfully repaired and parsed.\")\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"‚ùå JSON parse failed even after repair.\")\n",
        "            return None\n",
        "\n",
        "    if not plan_dict:\n",
        "        return None\n",
        "            \n",
        "    # --- Step 2: Programmatic Correction ---\n",
        "    room_type_map = {\n",
        "        \"living\": \"living_room\",\n",
        "        \"dining\": \"dining_room\",\n",
        "        \"master_bedroom\": \"master_bedroom\",\n",
        "        \"bedroom\": \"bedroom\",\n",
        "        \"kitchen\": \"kitchen\",\n",
        "        \"bathroom\": \"bathroom\",\n",
        "        \"study\": \"study\",\n",
        "        \"terrace\": \"balcony\",\n",
        "        \"roof_deck\": \"balcony\",\n",
        "        \"roof\": \"balcony\",\n",
        "        \"walk_in_closet\": \"storage\",\n",
        "        \"private_gym\": \"study\",\n",
        "    }\n",
        "    \n",
        "    if \"levels\" not in plan_dict or not isinstance(plan_dict[\"levels\"], list):\n",
        "        plan_dict[\"levels\"] = []\n",
        "\n",
        "    for level in plan_dict.get(\"levels\", []):\n",
        "        for room in level.get(\"rooms\", []):\n",
        "            # Correct room types\n",
        "            room_type = room.get(\"type\")\n",
        "            if room_type in room_type_map:\n",
        "                corrected_type = room_type_map[room_type]\n",
        "                print(f\"Correcting room type: '{room_type}' -> '{corrected_type}'\")\n",
        "                room[\"type\"] = corrected_type\n",
        "            \n",
        "            # Fix missing room_id in windows\n",
        "            room_id = room.get(\"id\")\n",
        "            if room_id:\n",
        "                for window in room.get(\"windows\", []):\n",
        "                    if \"room_id\" not in window:\n",
        "                        print(f\"Injecting missing room_id '{room_id}' into window.\")\n",
        "                        window[\"room_id\"] = room_id\n",
        "            \n",
        "            # Sanitize doors: rebuild the list, keeping only valid ones\n",
        "            valid_doors = []\n",
        "            for door in room.get(\"doors\", []):\n",
        "                # RUTHLESSLY DELETE doors missing required fields\n",
        "                if \"room1\" not in door or \"room2\" not in door:\n",
        "                    print(f\"Sanitizing: Removing door from '{room_id}' because it's missing room1/room2.\")\n",
        "                    continue\n",
        "\n",
        "                # Fix invalid door types\n",
        "                if door.get(\"type\") not in VALID_DOOR_TYPES:\n",
        "                    original_door_type = door.get(\"type\")\n",
        "                    door[\"type\"] = \"interior\"\n",
        "                    print(f\"Correcting invalid door type: '{original_door_type}' -> 'interior'\")\n",
        "                \n",
        "                # Fix invented room1_id/room2_id fields\n",
        "                if \"room1_id\" in door:\n",
        "                    door[\"room1\"] = door.pop(\"room1_id\")\n",
        "                    print(f\"Correcting door field: 'room1_id' -> 'room1'\")\n",
        "                if \"room2_id\" in door:\n",
        "                    door[\"room2\"] = door.pop(\"room2_id\")\n",
        "                    print(f\"Correcting door field: 'room2_id' -> 'room2'\")\n",
        "                \n",
        "                valid_doors.append(door)\n",
        "            room[\"doors\"] = valid_doors\n",
        "\n",
        "    return plan_dict\n",
        "\n",
        "\n",
        "# --- Execution ---\n",
        "print(\"--- Starting Data Factory Run (Parallel Mode) ---\")\n",
        "Path(DRIVE_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 1. Load all available prompts from central file\n",
        "all_prompts = []\n",
        "try:\n",
        "    with open(DRIVE_PROMPT_FILE, 'r') as f:\n",
        "        all_prompts = [line.strip() for line in f if line.strip()]\n",
        "    if not all_prompts:\n",
        "        raise FileNotFoundError\n",
        "    print(f\"‚úÖ Found {len(all_prompts)} total prompts in the master list.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå MASTER PROMPT FILE NOT FOUND at '{DRIVE_PROMPT_FILE}'.\")\n",
        "    print(\"Please run Cell 4 to generate it before running this cell.\")\n",
        "\n",
        "# 2. Select a random batch to process\n",
        "if all_prompts:\n",
        "    random.shuffle(all_prompts)\n",
        "    prompts_to_process = all_prompts[:NUM_PLANS_TO_GENERATE]\n",
        "    print(f\"‚úÖ This run will process a random batch of {len(prompts_to_process)} prompts.\")\n",
        "\n",
        "    for i, prompt_text in enumerate(prompts_to_process):\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(f\"Processing prompt {i+1}/{len(prompts_to_process)}\")\n",
        "        \n",
        "        prompt_hash = hashlib.sha1(prompt_text.encode()).hexdigest()[:16]\n",
        "        run_name = f\"plan_{prompt_hash}\"\n",
        "        output_file = Path(DRIVE_OUTPUT_DIR) / f\"{run_name}.json\"\n",
        "\n",
        "        if output_file.exists():\n",
        "            print(f\"‚è≠Ô∏è Skipping prompt, output file already exists: {output_file.name}\")\n",
        "            continue\n",
        "\n",
        "        print(textwrap.shorten(prompt_text, width=100, placeholder=\"...\"))\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        # --- STAGE 1 ---\n",
        "        print(\"Running Stage 1: Layout Generation...\")\n",
        "        stage_1_prompt = STAGE_1_PROMPT_TEMPLATE.format(\n",
        "            user_prompt=prompt_text,\n",
        "            valid_room_types=VALID_ROOM_TYPES\n",
        "        )\n",
        "        stage_1_response = call_ollama_colab(MODEL_NAME, stage_1_prompt)\n",
        "\n",
        "        if not stage_1_response:\n",
        "            print(\"‚ùå Stage 1 Failed: No response from model.\")\n",
        "            continue\n",
        "        \n",
        "        # --- STAGE 2 ---\n",
        "        print(\"Running Stage 2: Adding Openings...\")\n",
        "        stage_2_prompt = STAGE_2_PROMPT_TEMPLATE.format(\n",
        "            existing_layout=stage_1_response,\n",
        "            user_prompt=prompt_text,\n",
        "            valid_room_types=VALID_ROOM_TYPES,\n",
        "            valid_window_types=VALID_WINDOW_TYPES,\n",
        "            valid_door_types=VALID_DOOR_TYPES\n",
        "        )\n",
        "        stage_2_response = call_ollama_colab(MODEL_NAME, stage_2_prompt)\n",
        "        \n",
        "        if not stage_2_response:\n",
        "            print(\"‚ùå Stage 2 Failed: No response from model.\")\n",
        "            continue\n",
        "\n",
        "        # --- STAGE 2.5: Repair and Correct ---\n",
        "        print(\"Running Stage 2.5: Repairing and Correcting Plan...\")\n",
        "        corrected_plan = repair_and_correct_plan(stage_2_response, MODEL_NAME)\n",
        "        if not corrected_plan:\n",
        "            print(\"‚ùå Stage 2.5 Failed: Could not produce a valid plan.\")\n",
        "            with open(str(output_file).replace('.json', '_failed_repair.txt'), 'w') as f: f.write(stage_2_response)\n",
        "            continue\n",
        "\n",
        "        # --- STAGE 3: Finalize & Validate ---\n",
        "        print(\"Running Stage 3: Finalizing and Validating...\")\n",
        "        try:\n",
        "            processed_levels = corrected_plan.get(\"levels\", [])\n",
        "            for level_idx, level in enumerate(processed_levels):\n",
        "                level['level_number'] = level_idx\n",
        "\n",
        "            total_area_sqft = sum(\n",
        "                r['bounds']['width'] * r['bounds']['height']\n",
        "                for l in processed_levels\n",
        "                for r in l.get(\"rooms\", [])\n",
        "            )\n",
        "            \n",
        "            final_plan = {\n",
        "                \"input\": {\n",
        "                    \"basicDetails\": {\n",
        "                        \"prompt\": prompt_text, \n",
        "                        \"totalArea\": total_area_sqft,\n",
        "                        \"unit\": \"sqft\",\n",
        "                        \"floors\": len(processed_levels),\n",
        "                        \"bedrooms\": 0, # Placeholder\n",
        "                        \"bathrooms\": 0, # Placeholder\n",
        "                        \"style\": \"unknown\", # Placeholder\n",
        "                        \"budget\": 0 # Placeholder\n",
        "                    },\n",
        "                    \"plot\": {}, \"roomBreakdown\": []\n",
        "                },\n",
        "                \"levels\": processed_levels,\n",
        "                \"total_area\": round(total_area_sqft, 2),\n",
        "                \"construction_cost\": 0.0, \"materials\": {}, \"render_paths\": {}\n",
        "            }\n",
        "            \n",
        "            HouseOutput.model_validate(final_plan)\n",
        "\n",
        "            with open(output_file, 'w') as f:\n",
        "                json.dump(final_plan, f, indent=2)\n",
        "            print(f\"‚úÖ SUCCESS! Saved validated plan to {output_file}\")\n",
        "\n",
        "        except ValidationError as e:\n",
        "            print(f\"‚ùå Stage 3 Failed: Pydantic validation error - {e}\")\n",
        "            with open(str(output_file).replace('.json', '_failed_validation.txt'), 'w') as f: json.dump(corrected_plan, f, indent=2)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Stage 3 Failed: An unexpected error occurred - {e}\")\n",
        "            with open(str(output_file).replace('.json', '_failed_exception.txt'), 'w') as f: json.dump(corrected_plan, f, indent=2)\n",
        "    \n",
        "    print(\"\\nüéâ Data Factory run complete!\")\n",
        "else:\n",
        "    print(\"No prompts to process.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 4. (One-Time Setup) Generate Master Prompt File\n",
        "# @markdown This cell uses the `generate_prompts.py` script to create your master prompt file in Google Drive.\n",
        "# @markdown **You only need to run this cell once.**\n",
        "# @markdown Once the file is created, Cell 3 will be able to read from it for all future runs.\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Configuration ---\n",
        "#@markdown The desired location in your Google Drive for the master prompt file. This MUST match the path in Cell 3.\n",
        "DRIVE_PROMPT_FILE = \"/content/drive/MyDrive/housebrain_prompts/platinum_prompts.txt\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown The total number of prompts to generate for your master list.\n",
        "NUM_PROMPTS_TO_GENERATE = 30000 #@param {type:\"integer\"}\n",
        "# --- End Configuration ---\n",
        "\n",
        "# --- Execution ---\n",
        "REPO_DIR = \"/content/HouseBrainLLM\"\n",
        "script_path = os.path.join(REPO_DIR, \"scripts/generate_prompts.py\")\n",
        "\n",
        "# Ensure the repository is in the correct directory\n",
        "os.chdir(REPO_DIR)\n",
        "\n",
        "# Ensure the target directory in Drive exists\n",
        "Path(DRIVE_PROMPT_FILE).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Running prompt generation script to create {NUM_PROMPTS_TO_GENERATE} prompts...\")\n",
        "# Use an f-string for safer command construction\n",
        "command = f'python3 \"{script_path}\" --num-prompts {NUM_PROMPTS_TO_GENERATE} --output-file \"{DRIVE_PROMPT_FILE}\"'\n",
        "!{command}\n",
        "\n",
        "print(\"\\n--- Verification ---\")\n",
        "if Path(DRIVE_PROMPT_FILE).exists():\n",
        "    print(f\"‚úÖ Master prompt file successfully created at: {DRIVE_PROMPT_FILE}\")\n",
        "    print(\"First 5 prompts in the file:\")\n",
        "    !head -n 5 \"{DRIVE_PROMPT_FILE}\"\n",
        "else:\n",
        "    print(f\"‚ùå ERROR: Master prompt file was not created. Please check for errors above.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 5. (Optional) Download Generated Dataset\n",
        "# @markdown Run this cell after the data generation is complete to compress and download the entire output folder.\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "from datetime import datetime\n",
        "\n",
        "# Define the source directory in Google Drive. This should match DRIVE_OUTPUT_DIR from Cell 3.\n",
        "source_dir = \"/content/drive/MyDrive/housebrain_platinum_dataset\"\n",
        "\n",
        "# Create a timestamped zip filename\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "zip_filename = f\"housebrain_dataset_{timestamp}.zip\"\n",
        "zip_filepath = f\"/content/{zip_filename}\"\n",
        "\n",
        "if os.path.exists(source_dir) and os.listdir(source_dir):\n",
        "    # Create the zip archive\n",
        "    print(f\"Compressing '{source_dir}' into '{zip_filepath}'...\")\n",
        "    shutil.make_archive(zip_filepath.replace('.zip', ''), 'zip', source_dir)\n",
        "    print(\"‚úÖ Compression complete.\")\n",
        "\n",
        "    # Provide a download link\n",
        "    print(f\"\\nDownloading '{zip_filename}'...\")\n",
        "    files.download(zip_filepath)\n",
        "else:\n",
        "    print(f\"‚ùå ERROR: The source directory '{source_dir}' was not found or is empty. Please ensure the Data Factory ran correctly.\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
