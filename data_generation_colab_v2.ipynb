{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HouseBrain Data Factory 2.0: The Architect's Assembly Line\n",
        "\n",
        "This notebook is the control center for generating a high-quality, architecturally-sound dataset for training the HouseBrain LLM. It leverages the \"Architect's Assembly Line\" script, which is a robust, multi-stage pipeline designed to guide an LLM in creating valid house plans.\n",
        "\n",
        "**Our Strategy:**\n",
        "1.  **Use a powerful \"Generator\" model** (e.g., `qwen2:7b`, as recommended) within the pipeline to create draft plans.\n",
        "2.  **Run the pipeline at scale** on a large list of diverse architectural prompts.\n",
        "3.  **Save the validated, \"Gold Standard\" outputs** directly to your Google Drive.\n",
        "4.  Use this curated dataset in a separate notebook to fine-tune a more specialized \"Architect\" model (e.g., `Llama 3`).\n",
        "\n",
        "## Instructions\n",
        "1.  **Set Your GitHub PAT**: In the \"Setup\" section, you will be prompted to enter a GitHub Personal Access Token. This is required to clone the private `HouseBrainLLM` repository.\n",
        "2.  **Define Your Prompts**: In the \"Run Data Factory\" section, a default list of prompts is provided. You should replace or extend this with a much larger and more diverse list for a full data generation run.\n",
        "3.  **Run All Cells**: Once configured, select \"Runtime\" -> \"Run all\" from the menu. The notebook will set up the environment, download the necessary models, and begin the data generation process, saving the results to your Google Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 1. Setup Environment\n",
        "# @markdown Mount Google Drive and clone the repository using a secure token.\n",
        "from google.colab import drive\n",
        "import os\n",
        "import getpass\n",
        "import subprocess\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"‚úÖ Google Drive mounted.\")\n",
        "\n",
        "# --- GitHub Setup ---\n",
        "#@markdown Enter your GitHub Personal Access Token (PAT) with repo access.\n",
        "GITHUB_TOKEN = getpass.getpass('Enter your GitHub PAT: ')\n",
        "REPO_URL = f\"https://{GITHUB_TOKEN}@github.com/Vinay-O/HouseBrainLLM.git\"\n",
        "REPO_DIR = \"/content/HouseBrainLLM\"\n",
        "\n",
        "# Clone the repository\n",
        "if os.path.exists(REPO_DIR):\n",
        "    print(\"Repository already exists. Pulling latest changes...\")\n",
        "    subprocess.run(f\"cd {REPO_DIR} && git pull\", shell=True, check=True)\n",
        "else:\n",
        "    print(\"Cloning repository...\")\n",
        "    subprocess.run(f\"git clone {REPO_URL} {REPO_DIR}\", shell=True, check=True)\n",
        "\n",
        "print(\"‚úÖ Repository is ready.\")\n",
        "\n",
        "# --- Install Dependencies ---\n",
        "#@markdown Install necessary Python packages.\n",
        "!pip install -q pydantic GitPython\n",
        "\n",
        "print(\"‚úÖ Dependencies installed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 2. Configure and Start Ollama Server\n",
        "# @markdown This cell will download and start the Ollama server, then pull the specified model.\n",
        "# @markdown The process will take a few minutes.\n",
        "\n",
        "MODEL_NAME = \"mixtral:instruct\" # @param [\"mixtral:instruct\", \"qwen2:7b\", \"llama3:8b\", \"mistral:7b-instruct\", \"qwen2:72b\"]\n",
        "\n",
        "# Download and start Ollama\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "import threading\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "def run_ollama():\n",
        "    try:\n",
        "        subprocess.run(\"ollama serve\", shell=True, check=True, capture_output=True, text=True)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Ollama server failed: {e.stderr}\")\n",
        "\n",
        "print(\"üöÄ Starting Ollama server in the background...\")\n",
        "ollama_thread = threading.Thread(target=run_ollama)\n",
        "ollama_thread.daemon = True\n",
        "ollama_thread.start()\n",
        "\n",
        "# Wait for the server to be ready\n",
        "print(\"‚è≥ Waiting for Ollama server to initialize...\")\n",
        "time.sleep(10)\n",
        "\n",
        "# Pull the model\n",
        "print(f\"üì¶ Pulling model: {MODEL_NAME}. This may take a while...\")\n",
        "try:\n",
        "    subprocess.run(f\"ollama pull {MODEL_NAME}\", shell=True, check=True, capture_output=True, text=True)\n",
        "    print(f\"‚úÖ Model {MODEL_NAME} is ready.\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Failed to pull model. Trying default tag...\")\n",
        "    base_model = MODEL_NAME.split(':')[0]\n",
        "    subprocess.run(f\"ollama pull {base_model}\", shell=True, check=True)\n",
        "    print(f\"‚úÖ Model {base_model} is ready.\")\n",
        "\n",
        "# Verify Ollama is running\n",
        "!ollama list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 3. Run a 10-Plan Mock Run with A+ Prompts\n",
        "# @markdown This cell has been modified to run a small-scale, 10-prompt test using the latest high-quality prompt templates.\n",
        "# @markdown This will validate the prompt strategy before you launch a full-scale generation run.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import textwrap\n",
        "import logging\n",
        "from pathlib import Path\n",
        "import urllib.request\n",
        "import urllib.error\n",
        "from inspect import getsource\n",
        "from pydantic import BaseModel, ValidationError\n",
        "\n",
        "# --- Setup Paths and Logging ---\n",
        "REPO_DIR = \"/content/HouseBrainLLM\"\n",
        "if REPO_DIR not in sys.path:\n",
        "    sys.path.insert(0, REPO_DIR)\n",
        "os.chdir(REPO_DIR)\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# --- Import Schema from Cloned Repo ---\n",
        "try:\n",
        "    from src.housebrain.schema import HouseOutput, RoomType\n",
        "    print(\"‚úÖ Successfully imported HouseBrain schema.\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Failed to import HouseBrain schema: {e}\")\n",
        "    print(\"Please ensure the repository was cloned correctly in Step 1.\")\n",
        "\n",
        "# --- Self-Contained Generation Logic (with A+ Prompts) ---\n",
        "\n",
        "VALID_ROOM_TYPES = [e.value for e in RoomType]\n",
        "\n",
        "STAGE_1_PROMPT_TEMPLATE = f\"\"\"You are an expert AI architect. Your task is to generate ONLY the high-level geometric layout for a house based on a user's prompt.\n",
        "\n",
        "**CRITICAL INSTRUCTIONS:**\n",
        "1.  Focus ONLY on `levels` and `rooms`.\n",
        "2.  Rooms MUST have an `id`, `type`, and non-overlapping `bounds`.\n",
        "3.  The `type` for each room MUST be one of the following valid options: `{VALID_ROOM_TYPES}`. Do NOT invent new types.\n",
        "4.  DO NOT include `doors` or `windows` in this stage.\n",
        "5.  Your output MUST be a single, valid JSON object with a root \"levels\" key.\n",
        "\n",
        "**Golden Example of a perfect room structure:**\n",
        "```json\n",
        "{{\n",
        "  \"id\": \"living_room_0\",\n",
        "  \"type\": \"living_room\",\n",
        "  \"bounds\": {{\"x\": 10, \"y\": 10, \"width\": 20, \"height\": 15}}\n",
        "}}\n",
        "```\n",
        "---\n",
        "**User Prompt:**\n",
        "{{user_prompt}}\n",
        "---\n",
        "Now, generate the JSON for the house layout, adhering strictly to the instructions provided.\"\"\"\n",
        "\n",
        "STAGE_2_PROMPT_TEMPLATE = f\"\"\"You are an expert AI architect. Your task is to add `doors` and `windows` to a pre-existing house layout.\n",
        "\n",
        "**CRITICAL INSTRUCTIONS:**\n",
        "1.  Use the official `RoomType` enum for all room `type` fields. Valid types are: `{VALID_ROOM_TYPES}`.\n",
        "2.  DO NOT change the existing `id`, `type`, or `bounds` of the rooms.\n",
        "3.  `Door` and `Window` objects MUST be complete and valid JSON objects, conforming to the schema.\n",
        "4.  Your final output must be a single JSON object containing ONLY the `levels` key.\n",
        "\n",
        "**Expert Design Hints:**\n",
        "-   Place doors to create a logical and efficient flow between connected rooms.\n",
        "-   Place windows on exterior walls to maximize natural light and capture views where appropriate.\n",
        "-   Ensure `Door` objects correctly link two adjacent rooms in the `room1` and `room2` fields.\n",
        "\n",
        "**Golden Example of a perfect room with openings (Pay close attention to the structure of Door and Window):**\n",
        "```json\n",
        "\"rooms\": [\n",
        "   {{\n",
        "     \"id\": \"living_room_0\",\n",
        "     \"type\": \"living_room\",\n",
        "     \"bounds\": {{ \"x\": 10, \"y\": 10, \"width\": 20, \"height\": 15 }},\n",
        "     \"doors\": [\n",
        "       {{\n",
        "         \"position\": {{ \"x\": 20, \"y\": 25 }},\n",
        "         \"width\": 3.0,\n",
        "         \"type\": \"interior\",\n",
        "         \"room1\": \"living_room_0\",\n",
        "         \"room2\": \"dining_room_0\"\n",
        "       }}\n",
        "     ],\n",
        "     \"windows\": [\n",
        "       {{\n",
        "         \"position\": {{ \"x\": 10, \"y\": 17.5 }},\n",
        "         \"width\": 8.0,\n",
        "         \"height\": 5.0,\n",
        "         \"type\": \"sliding\",\n",
        "         \"room_id\": \"living_room_0\"\n",
        "       }}\n",
        "     ]\n",
        "   }}\n",
        "]\n",
        "```\n",
        "---\n",
        "**Full Schema Reference for Door and Window:**\n",
        "```python\n",
        "class Point2D(BaseModel):\n",
        "    x: float\n",
        "    y: float\n",
        "\n",
        "class Door(BaseModel):\n",
        "    position: Point2D\n",
        "    width: float = 3.0\n",
        "    type: str = \"interior\"\n",
        "    room1: str\n",
        "    room2: str\n",
        "\n",
        "class Window(BaseModel):\n",
        "    position: Point2D\n",
        "    width: float\n",
        "    height: float = 4.0\n",
        "    type: str = \"fixed\"\n",
        "    room_id: str\n",
        "```\n",
        "---\n",
        "**Existing House Layout (Do not change this part):**\n",
        "```json\n",
        "{{existing_layout}}\n",
        "```\n",
        "---\n",
        "**Original User Prompt:**\n",
        "{{user_prompt}}\n",
        "---\n",
        "Now, add the doors and windows to the layout, following the format of the Golden Example and Schema Reference exactly.\"\"\"\n",
        "\n",
        "def call_ollama_colab(model_name: str, prompt: str):\n",
        "    \"\"\"A direct implementation of the Ollama API call for Colab.\"\"\"\n",
        "    url = \"http://localhost:11434/api/generate\"\n",
        "    data = {\"model\": model_name, \"prompt\": prompt, \"stream\": False, \"format\": \"json\"}\n",
        "    encoded_data = json.dumps(data).encode('utf-8')\n",
        "    req = urllib.request.Request(url, data=encoded_data, headers={'Content-Type': 'application/json'})\n",
        "    try:\n",
        "        with urllib.request.urlopen(req, timeout=900) as response:\n",
        "            if response.status == 200:\n",
        "                response_data = json.loads(response.read().decode('utf-8'))\n",
        "                return response_data.get(\"response\", \"\")\n",
        "    except urllib.error.HTTPError as e:\n",
        "        error_content = e.read().decode('utf-8')\n",
        "        logger.error(f\"HTTP Error: {e.code} {e.reason} - {error_content}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Unexpected error calling Ollama: {e}\")\n",
        "    return None\n",
        "\n",
        "# --- Configuration ---\n",
        "PROMPT_FILE_PATH = \"/content/platinum_prompts.txt\"\n",
        "DRIVE_OUTPUT_DIR = \"/content/drive/MyDrive/housebrain_mock_run\"\n",
        "MODEL_NAME = \"mixtral:instruct\" # This should match the model pulled in Cell 2\n",
        "\n",
        "# --- Execution ---\n",
        "print(\"--- Starting Mock Run ---\")\n",
        "Path(DRIVE_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 1. Load prompts\n",
        "prompts = []\n",
        "try:\n",
        "    with open(PROMPT_FILE_PATH, 'r') as f:\n",
        "        prompts = [line.strip() for line in f if line.strip()]\n",
        "    if not prompts:\n",
        "        raise FileNotFoundError\n",
        "    # Use only the first 10 for the mock run\n",
        "    prompts = prompts[:10]\n",
        "    print(f\"‚úÖ Loaded {len(prompts)} prompts for the mock run.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: Prompt file not found at {PROMPT_FILE_PATH}.\")\n",
        "    print(\"Please run Cell 4 to generate it before running this cell.\")\n",
        "\n",
        "# 2. Run generation loop\n",
        "if prompts:\n",
        "    for i, prompt_text in enumerate(prompts):\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(f\"Processing prompt {i+1}/{len(prompts)}\")\n",
        "        print(textwrap.shorten(prompt_text, width=100, placeholder=\"...\"))\n",
        "        print(\"=\"*50)\n",
        "        \n",
        "        run_name = f\"prompt_{i+1:04d}\"\n",
        "        output_file = Path(DRIVE_OUTPUT_DIR) / f\"{run_name}.json\"\n",
        "\n",
        "        # --- STAGE 1 ---\n",
        "        print(\"Running Stage 1: Layout Generation...\")\n",
        "        stage_1_prompt = STAGE_1_PROMPT_TEMPLATE.format(user_prompt=prompt_text)\n",
        "        stage_1_response = call_ollama_colab(MODEL_NAME, stage_1_prompt)\n",
        "\n",
        "        if not stage_1_response:\n",
        "            print(\"‚ùå Stage 1 Failed: No response from model.\")\n",
        "            continue\n",
        "        \n",
        "        # --- STAGE 2 ---\n",
        "        print(\"Running Stage 2: Adding Openings...\")\n",
        "        stage_2_prompt = STAGE_2_PROMPT_TEMPLATE.format(existing_layout=stage_1_response, user_prompt=prompt_text)\n",
        "        stage_2_response = call_ollama_colab(MODEL_NAME, stage_2_prompt)\n",
        "        \n",
        "        if not stage_2_response:\n",
        "            print(\"‚ùå Stage 2 Failed: No response from model.\")\n",
        "            continue\n",
        "\n",
        "        # --- STAGE 3: Finalize & Validate ---\n",
        "        print(\"Running Stage 3: Finalizing and Validating...\")\n",
        "        try:\n",
        "            layout_with_openings = json.loads(stage_2_response)\n",
        "            \n",
        "            # **FIXED LOGIC**: Re-implementing the finalization from the assembly line script\n",
        "            # 1. Calculate total area\n",
        "            total_area_sqft = sum(\n",
        "                r['bounds']['width'] * r['bounds']['height']\n",
        "                for l in layout_with_openings.get(\"levels\", [])\n",
        "                for r in l.get(\"rooms\", [])\n",
        "            )\n",
        "            \n",
        "            # 2. Construct the final, complete object\n",
        "            final_plan = {\n",
        "                \"input\": {\n",
        "                    \"basicDetails\": {\"prompt\": prompt_text, \"totalArea\": total_area_sqft},\n",
        "                    \"plot\": {},\n",
        "                    \"roomBreakdown\": []\n",
        "                },\n",
        "                \"levels\": layout_with_openings.get(\"levels\", []),\n",
        "                \"total_area\": round(total_area_sqft, 2),\n",
        "                # Adding placeholder fields to ensure full schema compliance\n",
        "                \"construction_cost\": 0.0,\n",
        "                \"materials\": {},\n",
        "                \"render_paths\": {}\n",
        "            }\n",
        "            \n",
        "            # 3. Validate with Pydantic\n",
        "            HouseOutput.model_validate(final_plan)\n",
        "\n",
        "            with open(output_file, 'w') as f:\n",
        "                json.dump(final_plan, f, indent=2)\n",
        "            print(f\"‚úÖ SUCCESS! Saved validated plan to {output_file}\")\n",
        "\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"‚ùå Stage 3 Failed: Could not decode JSON from Stage 2.\")\n",
        "            # Save the failed response for debugging\n",
        "            with open(str(output_file).replace('.json', '_failed.txt'), 'w') as f:\n",
        "              f.write(stage_2_response)\n",
        "        except ValidationError as e:\n",
        "            print(f\"‚ùå Stage 3 Failed: Pydantic validation error - {e}\")\n",
        "            # Save the failed response for debugging\n",
        "            with open(str(output_file).replace('.json', '_failed.txt'), 'w') as f:\n",
        "              f.write(stage_2_response)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Stage 3 Failed: An unexpected error occurred - {e}\")\n",
        "            # Save the failed response for debugging\n",
        "            with open(str(output_file).replace('.json', '_failed.txt'), 'w') as f:\n",
        "              f.write(stage_2_response)\n",
        "    \n",
        "    print(\"\\nüéâ Mock run complete!\")\n",
        "else:\n",
        "    print(\"No prompts to process.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 4. (Optional) Create `platinum_prompts.txt` for Large-Scale Runs\n",
        "# @markdown Run this cell **once** to create the `platinum_prompts.txt` file in your Colab environment.\n",
        "# @markdown You can then modify the cell above (Cell 3) to read prompts from this file instead of the small list.\n",
        "\n",
        "import random\n",
        "\n",
        "# --- Components for Prompt Generation ---\n",
        "STYLES = [\n",
        "    \"Modern\", \"Contemporary\", \"Minimalist\", \"Traditional Kerala-style 'Nalukettu'\",\n",
        "    \"Colonial\", \"Industrial\", \"Scandinavian\", \"Bohemian\", \"Farmhouse\", \"Chettinad-style\",\n",
        "    \"Eco-friendly\", \"Brutalist\", \"Art Deco\", \"Mediterranean\"\n",
        "]\n",
        "SIZES_BHK = [\"1BHK\", \"2BHK\", \"3BHK\", \"4BHK\", \"5BHK\", \"6BHK\", \"studio apartment\"]\n",
        "SIZES_SQFT = [\n",
        "    \"800 sqft\", \"1000 sqft\", \"1200 sqft\", \"1500 sqft\", \"1800 sqft\",\n",
        "    \"2000 sqft\", \"2500 sqft\", \"3000 sqft\", \"4000 sqft\", \"5000 sqft\"\n",
        "]\n",
        "FLOORS = [\n",
        "    \"single-story\", \"two-story\", \"G+1\", \"G+2\", \"duplex\", \"triplex\",\n",
        "    \"split-level\", \"penthouse\"\n",
        "]\n",
        "STRUCTURE_TYPES = [\"house\", \"villa\", \"apartment\", \"bungalow\", \"farmhouse\", \"townhouse\", \"cottage\"]\n",
        "PLOT_SIZES = [\n",
        "    \"30x40 feet\", \"30x50 feet\", \"40x60 feet\", \"50x80 feet\", \"60x90 feet\",\n",
        "    \"80x100 feet\", \"100x100 feet\", \"corner\", \"irregular\"\n",
        "]\n",
        "FEATURES = [\n",
        "    \"with an open-plan kitchen and living area\", \"with a swimming pool\", \"with a home theater\",\n",
        "    \"with a large garden\", \"with a central courtyard\", \"with a dedicated home office\",\n",
        "    \"with a private gym\", \"featuring floor-to-ceiling windows\", \"with a rooftop terrace\",\n",
        "    \"with a two-car garage\", \"with servant's quarters\", \"with a library\", \"with a spacious balcony for each bedroom\"\n",
        "]\n",
        "CONSTRAINTS = [\n",
        "    \"and be Vastu-compliant\", \"with a North-facing entrance\", \"with a West-facing plot\",\n",
        "    \"on a tight budget\", \"for a luxury segment\", \"designed for a family of four\",\n",
        "    \"with a focus on natural light and ventilation\", \"for a joint family\", \"as a bachelor pad\",\n",
        "    \"to be wheelchair accessible\"\n",
        "]\n",
        "\n",
        "def generate_prompt():\n",
        "    prompt_parts = []\n",
        "    style = random.choice(STYLES)\n",
        "    num_floors = random.choice(FLOORS)\n",
        "    bhk = random.choice(SIZES_BHK)\n",
        "    structure = random.choice(STRUCTURE_TYPES)\n",
        "    prompt_parts.append(f\"Design a {style}, {num_floors} {bhk} {structure}\")\n",
        "    if random.random() < 0.7:\n",
        "        plot = random.choice(PLOT_SIZES)\n",
        "        prompt_parts.append(f\"for a {plot} plot\")\n",
        "    else:\n",
        "        area = random.choice(SIZES_SQFT)\n",
        "        prompt_parts.append(f\"with a total area of {area}\")\n",
        "    num_features = random.randint(1, 3)\n",
        "    selected_features = random.sample(FEATURES, num_features)\n",
        "    prompt_parts.extend(selected_features)\n",
        "    if random.random() < 0.6:\n",
        "        num_constraints = random.randint(1, 2)\n",
        "        selected_constraints = random.sample(CONSTRAINTS, num_constraints)\n",
        "        prompt_parts.extend(selected_constraints)\n",
        "    return \". \".join(prompt_parts) + \".\"\n",
        "\n",
        "NUM_PROMPTS = 10000\n",
        "OUTPUT_FILE = \"/content/platinum_prompts.txt\"\n",
        "\n",
        "print(f\"Generating {NUM_PROMPTS} prompts and saving to {OUTPUT_FILE}...\")\n",
        "with open(OUTPUT_FILE, 'w') as f:\n",
        "    for i in range(NUM_PROMPTS):\n",
        "        prompt = generate_prompt()\n",
        "        f.write(f\"{prompt}\\\\n\")\n",
        "print(f\"‚úÖ Successfully generated and saved {NUM_PROMPTS} prompts.\")\n",
        "\n",
        "# Display the first 5 prompts to verify\n",
        "!head -n 5 {OUTPUT_FILE}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 5. (Optional) Download Generated Dataset\n",
        "# @markdown Run this cell after the data generation is complete to compress and download the entire output folder.\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Define the source directory in Google Drive and the target zip file path\n",
        "# This should match the DRIVE_OUTPUT_DIR from Cell 3\n",
        "source_dir = \"/content/drive/MyDrive/housebrain_dataset\"\n",
        "zip_filename = \"housebrain_dataset.zip\"\n",
        "zip_filepath = f\"/content/{zip_filename}\"\n",
        "\n",
        "if os.path.exists(source_dir):\n",
        "    # Create the zip archive\n",
        "    print(f\"Compressing '{source_dir}' into '{zip_filepath}'...\")\n",
        "    shutil.make_archive(zip_filepath.replace('.zip', ''), 'zip', source_dir)\n",
        "    print(\"‚úÖ Compression complete.\")\n",
        "\n",
        "    # Provide a download link\n",
        "    print(f\"\\nDownloading '{zip_filename}'...\")\n",
        "    files.download(zip_filepath)\n",
        "else:\n",
        "    print(f\"ERROR: The source directory '{source_dir}' was not found. Please ensure the Data Factory ran correctly.\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
