{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HouseBrain Data Factory 3.0: The Diamond Series\n",
        "\n",
        "This notebook is for generating the **Diamond Dataset**. The goal of this dataset is to teach our fine-tuned model how to handle **complex, conflicting, and unconventional** architectural challenges.\n",
        "\n",
        "**Our Strategy:**\n",
        "1.  **Use a specialized script** to generate a smaller, more focused list of 2,500 \"Diamond-tier\" prompts.\n",
        "2.  **Use our best \"Journeyman\" model** (fine-tuned on the Platinum dataset) as the generator to create draft plans.\n",
        "3.  **Save the validated outputs** to a new `housebrain_diamond_dataset` folder in your Google Drive.\n",
        "4.  Use this dataset for a second round of fine-tuning to elevate our model from a \"Journeyman\" to a \"Master Architect.\"\n",
        "\n",
        "## Instructions\n",
        "1.  **Set Your GitHub PAT**: Ensure your GitHub token is ready.\n",
        "2.  **Run All Cells**: The notebook will set up the environment, generate the complex prompts, and begin the data generation process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 1. Setup Environment\n",
        "# @markdown Mount Google Drive and clone the repository using a secure token.\n",
        "from google.colab import drive\n",
        "import os\n",
        "import getpass\n",
        "import subprocess\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"‚úÖ Google Drive mounted.\")\n",
        "\n",
        "# --- GitHub Setup ---\n",
        "#@markdown Enter your GitHub Personal Access Token (PAT) with repo access.\n",
        "GITHUB_TOKEN = getpass.getpass('Enter your GitHub PAT: ')\n",
        "REPO_URL = f\"https://{GITHUB_TOKEN}@github.com/Vinay-O/HouseBrainLLM.git\"\n",
        "REPO_DIR = \"/content/HouseBrainLLM\"\n",
        "\n",
        "# Clone the repository\n",
        "if os.path.exists(REPO_DIR):\n",
        "    print(\"Repository already exists. Pulling latest changes...\")\n",
        "    subprocess.run(f\"cd {REPO_DIR} && git pull\", shell=True, check=True)\n",
        "else:\n",
        "    print(\"Cloning repository...\")\n",
        "    subprocess.run(f\"git clone {REPO_URL} {REPO_DIR}\", shell=True, check=True)\n",
        "\n",
        "print(\"‚úÖ Repository is ready.\")\n",
        "\n",
        "# --- Install Dependencies ---\n",
        "#@markdown Install necessary Python packages.\n",
        "!pip install -q pydantic GitPython\n",
        "\n",
        "print(\"‚úÖ Dependencies installed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 2. Configure and Start Ollama Server\n",
        "# @markdown This cell will download and start the Ollama server, then pull the specified model.\n",
        "# @markdown **Important:** For the Diamond run, we should ideally use our fine-tuned \"Journeyman\" model. For now, we will continue to use a powerful base model like Mixtral.\n",
        "\n",
        "MODEL_NAME = \"mixtral:instruct\" # @param [\"mixtral:instruct\", \"qwen2:7b\", \"llama3:8b\", \"mistral:7b-instruct\"]\n",
        "\n",
        "# Download and start Ollama\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "import threading\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "def run_ollama():\n",
        "    try:\n",
        "        subprocess.run(\"ollama serve\", shell=True, check=True, capture_output=True, text=True)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Ollama server failed: {e.stderr}\")\n",
        "\n",
        "print(\"üöÄ Starting Ollama server in the background...\")\n",
        "ollama_thread = threading.Thread(target=run_ollama)\n",
        "ollama_thread.daemon = True\n",
        "ollama_thread.start()\n",
        "\n",
        "# Wait for the server to be ready\n",
        "print(\"‚è≥ Waiting for Ollama server to initialize...\")\n",
        "time.sleep(10)\n",
        "\n",
        "# Pull the model\n",
        "print(f\"üì¶ Pulling model: {MODEL_NAME}. This may take a while...\")\n",
        "try:\n",
        "    subprocess.run(f\"ollama pull {MODEL_NAME}\", shell=True, check=True, capture_output=True, text=True)\n",
        "    print(f\"‚úÖ Model {MODEL_NAME} is ready.\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Failed to pull model. Trying default tag...\")\n",
        "    base_model = MODEL_NAME.split(':')[0]\n",
        "    subprocess.run(f\"ollama pull {base_model}\", shell=True, check=True)\n",
        "    print(f\"‚úÖ Model {base_model} is ready.\")\n",
        "\n",
        "# Verify Ollama is running\n",
        "!ollama list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 3. Generate Diamond Prompts & Run the Factory\n",
        "# @markdown This cell first generates 2,500 complex prompts and then runs the assembly line for each one.\n",
        "\n",
        "import os\n",
        "from datetime import datetime\n",
        "import textwrap\n",
        "import subprocess\n",
        "\n",
        "# --- 1. Generate Diamond Prompts ---\n",
        "os.chdir(REPO_DIR)\n",
        "prompt_script_path = \"scripts/generate_diamond_prompts.py\"\n",
        "prompt_output_file = \"/content/diamond_prompts.txt\"\n",
        "num_diamond_prompts = 2500\n",
        "\n",
        "print(f\"--- Generating {num_diamond_prompts} Diamond-tier prompts ---\")\n",
        "prompt_command = [\n",
        "    \"python3\",\n",
        "    prompt_script_path,\n",
        "    \"--num-prompts\", str(num_diamond_prompts),\n",
        "    \"--output-file\", prompt_output_file\n",
        "]\n",
        "subprocess.run(prompt_command)\n",
        "print(f\"‚úÖ Diamond prompts saved to {prompt_output_file}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "\n",
        "# --- 2. Load Prompts ---\n",
        "print(f\"Loading prompts from {prompt_output_file}...\")\n",
        "try:\n",
        "    with open(prompt_output_file, 'r') as f:\n",
        "        prompts = [line.strip() for line in f if line.strip()]\n",
        "    print(f\"‚úÖ Successfully loaded {len(prompts)} prompts.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: Prompt file not found at {prompt_output_file}.\")\n",
        "    prompts = []\n",
        "\n",
        "# --- 3. Run the Data Factory ---\n",
        "#@markdown Specify the output directory in your Google Drive for the Diamond dataset.\n",
        "DRIVE_OUTPUT_DIR = \"/content/drive/MyDrive/housebrain_diamond_dataset\"\n",
        "\n",
        "if prompts:\n",
        "    assembly_line_script_path = \"scripts/run_complete_assembly_line.py\"\n",
        "    run_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    output_dir = os.path.join(DRIVE_OUTPUT_DIR, f\"run_{run_timestamp}\")\n",
        "\n",
        "    print(f\"\\nOutput directory is ready at: {output_dir}\")\n",
        "    print(f\"Found {len(prompts)} prompts to process.\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    for i, prompt in enumerate(prompts):\n",
        "        print(f\"Processing prompt {i+1}/{len(prompts)}\")\n",
        "        prompt_short = textwrap.shorten(prompt, width=100, placeholder=\"...\")\n",
        "        print(f\"PROMPT: {prompt_short}\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        run_name = f\"prompt_{i+1:04d}\"\n",
        "        command = [\n",
        "            \"python3\", assembly_line_script_path,\n",
        "            \"--prompt\", prompt,\n",
        "            \"--output-dir\", output_dir,\n",
        "            \"--run-name\", run_name,\n",
        "            \"--model\", MODEL_NAME,\n",
        "            \"--max-retries\", \"5\"\n",
        "        ]\n",
        "        subprocess.run(command)\n",
        "        print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "\n",
        "    print(\"üéâ Diamond Data Factory run complete! Check your Google Drive for the generated files.\")\n",
        "else:\n",
        "    print(\"No prompts to process. Please check your configuration.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ## 4. (Optional) Download Generated Diamond Dataset\n",
        "# @markdown Run this cell after the data generation is complete to compress and download the entire output folder.\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Define the source directory in Google Drive and the target zip file path\n",
        "source_dir = \"/content/drive/MyDrive/housebrain_diamond_dataset\"\n",
        "zip_filename = \"housebrain_diamond_dataset.zip\"\n",
        "zip_filepath = f\"/content/{zip_filename}\"\n",
        "\n",
        "if os.path.exists(source_dir):\n",
        "    print(f\"Compressing '{source_dir}' into '{zip_filepath}'...\")\n",
        "    shutil.make_archive(zip_filepath.replace('.zip', ''), 'zip', source_dir)\n",
        "    print(\"‚úÖ Compression complete.\")\n",
        "\n",
        "    # Provide a download link\n",
        "    print(f\"\\nDownloading '{zip_filename}'...\")\n",
        "    files.download(zip_filepath)\n",
        "else:\n",
        "    print(f\"ERROR: The source directory '{source_dir}' was not found. Please ensure the Data Factory ran correctly.\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
