{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# \ud83c\udfe0 HouseBrain LLM Training\n\n",
        "**Train your custom architectural AI on Google Colab/Kaggle (Free GPU)**\n\n",
        "This notebook will help you train your HouseBrain LLM using the enhanced 150K dataset.\n\n",
        "---\n\n",
        "## \ud83c\udfaf Training Strategy\n\n",
        "### **Option 1: Kaggle (Recommended)**\n",
        "- **GPU**: P100 (16GB VRAM)\n",
        "- **Training Time**: 5-7 hours\n",
        "- **Cost**: Free\n",
        "- **Quality**: Excellent\n\n",
        "### **Option 2: Colab**\n",
        "- **GPU**: T4 (16GB VRAM)\n",
        "- **Training Time**: 6-8 hours\n",
        "- **Cost**: Free\n",
        "- **Quality**: Very Good\n\n",
        "## \ud83d\udcca Enhanced Dataset Features\n\n",
        "Your 150K enhanced dataset includes:\n",
        "- **Plot Shape & Orientation**\n",
        "- **Exterior Finishes & Materials**\n",
        "- **Climate & Site Conditions**\n",
        "- **Building Codes & Regulations**\n",
        "- **Garage & Parking**\n",
        "- **Utilities & Accessibility**\n\n",
        "## \ud83d\ude80 Expected Results\n\n",
        "- **Training Loss**: < 0.8 (target), < 0.6 (excellent)\n",
        "- **Validation Loss**: < 1.0 (target), < 0.8 (excellent)\n",
        "- **Compliance Score**: 85-95% (excellent)\n",
        "- **Generation Speed**: < 10s per design\n",
        "- **Enhanced Output**: Includes all architectural parameters\n\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## \ud83d\ude80 Step 1: Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_deps"
      },
      "outputs": [],
      "source": [
        "# Install required dependencies\n",
        "!pip install torch transformers datasets accelerate peft bitsandbytes wandb tqdm fastapi uvicorn pydantic orjson svgwrite trimesh python-dotenv\n\n",
        "print(\"\u2705 Dependencies installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone_repo"
      },
      "outputs": [],
      "source": [
        "# Clone the HouseBrain repository\n",
        "!git clone https://github.com/Vinay-O/HouseBrainLLM.git\n",
        "%cd HouseBrainLLM\n\n",
        "print(\"\u2705 Repository cloned successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upload_dataset"
      },
      "source": [
        "## \ud83d\udce4 Step 2: Upload Enhanced Dataset\n\n",
        "Upload your 150K enhanced dataset zip file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload"
      },
      "outputs": [],
      "source": [
        "# Upload your enhanced dataset\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n\n",
        "print(\"\ud83d\udce4 Upload your enhanced dataset zip file...\")\n",
        "print(\"\ud83d\udca1 Upload: housebrain_dataset_v5_150k_colab.zip\")\n\n",
        "uploaded = files.upload()\n\n",
        "# Extract the dataset\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.zip'):\n",
        "        print(f\"\ud83d\udce6 Extracting {filename}...\")\n",
        "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "            zip_ref.extractall('.')\n",
        "        print(f\"\u2705 Dataset extracted successfully!\")\n",
        "        break\n\n",
        "# List extracted files\n",
        "print(\"\\n\ud83d\udcc1 Extracted files:\")\n",
        "for root, dirs, files in os.walk('.'):\n",
        "    if 'housebrain_dataset_v5_150k' in root:\n",
        "        print(f\"   {root}\")\n",
        "        for file in files[:5]:  # Show first 5 files\n",
        "            print(f\"     - {file}\")\n",
        "        if len(files) > 5:\n",
        "            print(f\"     ... and {len(files) - 5} more files\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "configure_training"
      },
      "source": [
        "## \u2699\ufe0f Step 3: Configure Training\n\n",
        "Set up your training parameters for the enhanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import_modules"
      },
      "outputs": [],
      "source": [
        "# Import training modules\n",
        "import sys\n",
        "sys.path.append('src')\n\n",
        "from housebrain.finetune import FineTuningConfig, HouseBrainFineTuner\n",
        "import torch\n\n",
        "print(\"\u2705 Training modules imported successfully!\")\n\n",
        "# Check GPU\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f\"\ud83d\ude80 GPU: {gpu_name} ({gpu_memory:.1f}GB VRAM)\")\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f  No GPU detected. Training will be very slow on CPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "training_config"
      },
      "outputs": [],
      "source": [
        "# Training configuration for 150K enhanced dataset\n",
        "config = FineTuningConfig(\n",
        "    model_name=\"deepseek-ai/deepseek-coder-6.7b-base\",\n",
        "    dataset_path=\"housebrain_dataset_v5_150k_colab\",  # Your dataset path\n",
        "    output_dir=\"models/housebrain-colab-trained\",\n",
        "    max_length=1024,\n",
        "    batch_size=2,  # Adjust based on GPU memory\n",
        "    num_epochs=3,\n",
        "    learning_rate=2e-4,\n",
        "    use_4bit=True,  # Use 4-bit quantization for memory efficiency\n",
        "    fp16=True,  # Use mixed precision training\n",
        "    warmup_steps=100,\n",
        "    logging_steps=50,\n",
        "    save_steps=500,\n",
        "    eval_steps=500,\n",
        "    gradient_accumulation_steps=4,\n",
        "    lora_r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        ")\n\n",
        "print(f\"\ud83d\udccb Training Configuration:\")\n",
        "print(f\"   Model: {config.model_name}\")\n",
        "print(f\"   Dataset: {config.dataset_path}\")\n",
        "print(f\"   Output: {config.output_dir}\")\n",
        "print(f\"   Samples: 150,000 enhanced\")\n",
        "print(f\"   Batch Size: {config.batch_size}\")\n",
        "print(f\"   Epochs: {config.num_epochs}\")\n",
        "print(f\"   Learning Rate: {config.learning_rate}\")\n",
        "print(f\"   4-bit Quantization: {config.use_4bit}\")\n",
        "print(f\"   Mixed Precision: {config.fp16}\")\n",
        "print(f\"   LoRA Rank: {config.lora_r}\")\n",
        "print(f\"   LoRA Alpha: {config.lora_alpha}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "start_training"
      },
      "source": [
        "## \ud83e\udde0 Step 4: Start Training\n\n",
        "Train your HouseBrain LLM on the enhanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "initialize_trainer"
      },
      "outputs": [],
      "source": [
        "# Initialize trainer\n",
        "print(\"\ud83d\udd27 Setting up trainer...\")\n",
        "trainer = HouseBrainFineTuner(config)\n",
        "print(\"\u2705 Trainer initialized successfully!\")\n",
        "print(f\"\\n\ud83d\udcca Training on enhanced dataset with:\")\n",
        "print(f\"   \u2022 Plot shape & orientation\")\n",
        "print(f\"   \u2022 Exterior finishes & materials\")\n",
        "print(f\"   \u2022 Climate & site conditions\")\n",
        "print(f\"   \u2022 Building codes & regulations\")\n",
        "print(f\"   \u2022 Garage & parking requirements\")\n",
        "print(f\"   \u2022 Utilities & accessibility\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train"
      },
      "outputs": [],
      "source": [
        "# Start training\n",
        "print(\"\ud83c\udfaf Starting training...\")\n",
        "print(\"\u23f0 This will take 5-7 hours on GPU\")\n",
        "print(\"\ud83d\udcca Training on 150K enhanced samples...\")\n",
        "print(\"\ud83d\udca1 Keep this notebook active and don't close the browser tab!\")\n\n",
        "try:\n",
        "    trainer.train()\n",
        "    print(\"\\n\ud83c\udf89 Training completed successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n\u274c Training failed: {e}\")\n",
        "    print(\"\ud83d\udca1 Check GPU memory or reduce batch size\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "save_model"
      },
      "source": [
        "## \ud83d\udcbe Step 5: Save Trained Model\n\n",
        "Save your trained model for later use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "print(\"\ud83d\udcbe Saving trained model...\")\n",
        "trainer.save_model()\n",
        "print(\"\u2705 Model saved successfully!\")\n\n",
        "# Create zip archive for download\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n\n",
        "model_dir = Path(config.output_dir)\n",
        "zip_path = \"housebrain-model-colab-150k.zip\"\n\n",
        "print(f\"\ud83d\udce6 Creating zip archive: {zip_path}\")\n",
        "print(\"\u23f0 This may take 2-3 minutes...\")\n\n",
        "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    for root, dirs, files in os.walk(model_dir):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            arcname = os.path.relpath(file_path, model_dir)\n",
        "            zipf.write(file_path, arcname)\n\n",
        "print(f\"\u2705 Zip archive created: {zip_path}\")\n",
        "print(f\"\ud83d\udcc1 Archive size: {os.path.getsize(zip_path) / 1e6:.1f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download_model"
      },
      "source": [
        "## \u2b07\ufe0f Step 6: Download Trained Model\n\n",
        "Download your trained model to your computer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download"
      },
      "outputs": [],
      "source": [
        "# Download the trained model\n",
        "from google.colab import files\n\n",
        "print(\"\u2b07\ufe0f  Downloading trained model...\")\n",
        "print(f\"\ud83d\udce6 File: {zip_path}\")\n",
        "print(f\"\ud83d\udcc1 Size: {os.path.getsize(zip_path) / 1e6:.1f} MB\")\n",
        "print(\"\ud83d\udca1 This may take a few minutes to download...\")\n\n",
        "files.download(zip_path)\n",
        "print(\"\u2705 Trained model downloaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "test_model"
      },
      "source": [
        "## \ud83e\uddea Step 7: Test Trained Model (Optional)\n\n",
        "Test your trained model with a sample input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test"
      },
      "outputs": [],
      "source": [
        "# Test the trained model\n",
        "print(\"\ud83e\uddea Testing trained model...\")\n\n",
        "# Sample input for testing\n",
        "test_input = {\n",
        "    \"basicDetails\": {\n",
        "        \"totalArea\": 2000,\n",
        "        \"unit\": \"sqft\",\n",
        "        \"bedrooms\": 3,\n",
        "        \"bathrooms\": 2,\n",
        "        \"floors\": 2,\n",
        "        \"budget\": 400000,\n",
        "        \"style\": \"Modern\"\n",
        "    },\n",
        "    \"plot\": {\n",
        "        \"length\": 50,\n",
        "        \"width\": 40,\n",
        "        \"unit\": \"ft\",\n",
        "        \"shape\": \"Rectangle\",\n",
        "        \"orientation\": \"S\",\n",
        "        \"slope_degrees\": 2.5,\n",
        "        \"is_corner_plot\": False,\n",
        "        \"setbacks_ft\": {\n",
        "            \"front\": 5,\n",
        "            \"rear\": 5,\n",
        "            \"left\": 3,\n",
        "            \"right\": 3\n",
        "        }\n",
        "    },\n",
        "    \"roomBreakdown\": [\n",
        "        {\"type\": \"master_bedroom\", \"count\": 1, \"minArea\": 200},\n",
        "        {\"type\": \"bedroom\", \"count\": 2, \"minArea\": 150},\n",
        "        {\"type\": \"bathroom\", \"count\": 2, \"minArea\": 60},\n",
        "        {\"type\": \"kitchen\", \"count\": 1, \"minArea\": 180},\n",
        "        {\"type\": \"livingRoom\", \"count\": 1, \"minArea\": 300},\n",
        "        {\"type\": \"diningRoom\", \"count\": 1, \"minArea\": 150}\n",
        "    ]\n",
        "}\n\n",
        "print(\"\ud83d\udccb Test Input:\")\n",
        "print(f\"   Area: {test_input['basicDetails']['totalArea']} sqft\")\n",
        "print(f\"   Bedrooms: {test_input['basicDetails']['bedrooms']}\")\n",
        "print(f\"   Floors: {test_input['basicDetails']['floors']}\")\n",
        "print(f\"   Style: {test_input['basicDetails']['style']}\")\n",
        "print(f\"   Plot Shape: {test_input['plot']['shape']}\")\n",
        "print(f\"   Orientation: {test_input['plot']['orientation']}\")\n\n",
        "# Test with trained model\n",
        "try:\n",
        "    from housebrain.llm import HouseBrainLLM\n",
        "    \n",
        "    llm = HouseBrainLLM(finetuned_model_path=config.output_dir)\n",
        "    result = llm.generate_design(test_input)\n",
        "    \n",
        "    print(\"\\n\u2705 Model test successful!\")\n",
        "    print(f\"\ud83d\udcca Generated design with {len(result.levels)} levels\")\n",
        "    print(f\"\ud83d\udcb0 Construction cost: ${result.construction_cost:,}\")\n",
        "    print(f\"\ud83d\udcd0 Total area: {result.total_area} sqft\")\n",
        "    \n",
        "    # Check for enhanced features\n",
        "    if hasattr(result, 'exterior_specifications'):\n",
        "        print(f\"\ud83c\udfe0 Exterior: {result.exterior_specifications.get('exterior_wall', 'Unknown')}\")\n",
        "    if hasattr(result, 'climate_and_site'):\n",
        "        print(f\"\ud83c\udf21\ufe0f  Climate: {result.climate_and_site.get('climate_zone', 'Unknown')}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\n\u274c Model test failed: {e}\")\n",
        "    print(\"\ud83d\udca1 This is normal if the model is still training or there are compatibility issues\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "next_steps"
      },
      "source": [
        "## \ud83c\udfaf Next Steps\n\n",
        "### 1. **Download Trained Model** \u2705\n",
        "Your trained HouseBrain LLM has been downloaded.\n\n",
        "### 2. **Use Locally**\n",
        "1. Extract the model zip file\n",
        "2. Place in your local HouseBrain project\n",
        "3. Use with the API or test scripts\n\n",
        "### 3. **Deploy**\n",
        "1. Upload to cloud platforms\n",
        "2. Integrate with web applications\n",
        "3. Use for architectural design services\n\n",
        "### 4. **Evaluate Performance**\n",
        "1. Test with various inputs\n",
        "2. Compare with baseline models\n",
        "3. Measure compliance scores\n\n",
        "---\n\n",
        "## \ud83d\udcca Training Results Summary\n\n",
        "### **Dataset Used**\n",
        "- **Size**: 150,000 enhanced samples\n",
        "- **Features**: 6+ crucial architectural parameters\n",
        "- **Quality**: Excellent diversity and realism\n\n",
        "### **Model Performance**\n",
        "- **Base Model**: DeepSeek Coder 6.7B\n",
        "- **Fine-tuning**: QLoRA (LoRA + 4-bit quantization)\n",
        "- **Training Time**: 5-7 hours\n",
        "- **Expected Compliance**: 85-95%\n\n",
        "### **Enhanced Features Learned**\n",
        "- **Plot Shape & Orientation**: Rectangle, L-shape, corner plot, etc.\n",
        "- **Exterior Finishes**: Brick, stone, stucco, vinyl, wood, concrete\n",
        "- **Climate Adaptation**: Hot, cold, tropical, Mediterranean zones\n",
        "- **Building Codes**: FAR, height limits, parking requirements\n",
        "- **Site Conditions**: Soil types, utilities, accessibility\n\n",
        "## \ud83c\udd98 Troubleshooting\n\n",
        "### **Out of Memory**\n",
        "- Reduce `batch_size` to 1\n",
        "- Use smaller model: `deepseek-ai/deepseek-coder-1.3b-base`\n",
        "- Reduce `max_length` to 512\n\n",
        "### **Slow Training**\n",
        "- Increase `gradient_accumulation_steps` to 8\n",
        "- Use `fp16=True` (already enabled)\n",
        "- Reduce `num_epochs` to 2\n\n",
        "### **Poor Results**\n",
        "- Check dataset quality\n",
        "- Increase `learning_rate` to 3e-4\n",
        "- Increase `lora_r` to 32\n\n",
        "---\n\n",
        "**\ud83c\udf89 Congratulations! You've successfully trained your HouseBrain LLM!**\n\n",
        "**Your model now understands all crucial architectural parameters and can generate high-quality house designs!**\n\n",
        "For more information, visit: https://github.com/Vinay-O/HouseBrainLLM"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}