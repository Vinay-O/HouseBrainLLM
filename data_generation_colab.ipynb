{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HouseBrain: Automated Data Factory ðŸ­\n",
        "\n",
        "This notebook is a dedicated environment for generating a large, high-quality dataset of architectural plans. It implements a hybrid-model `Generate -> Analyze -> Repair` pipeline.\n",
        "\n",
        "**Workflow:**\n",
        "1.  **Setup:** Mounts Google Drive, clones the repository using a secure token prompt, and installs dependencies.\n",
        "2.  **Ollama Server:** Installs and runs the Ollama server in the background.\n",
        "3.  **Model Provisioning:** Pulls two models: a fast model for initial generation (`llama3:8b`) and a powerful model for repairs (`qwen3:30b`).\n",
        "4.  **Prompt Loading:** Creates a `prompts.txt` file to serve as the workload for the factory.\n",
        "5.  **Automated Curation:** For each prompt, it runs an orchestration script which:\n",
        "    a.  **Generates** a draft using the fast `llama3:8b`.\n",
        "    b.  **Analyzes** the draft for errors.\n",
        "    c.  **Repairs** the draft using the powerful `qwen3:30b` if needed.\n",
        "6.  **Output:** Saves the final, validated \"Gold Standard\" JSON files directly to your Google Drive.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup Environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive to persist our dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Securely provide your GitHub token to clone the private repository\n",
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "# Prompt for the GitHub token\n",
        "github_token = getpass('Enter your GitHub Personal Access Token (PAT): ')\n",
        "os.environ['GITHUB_TOKEN'] = github_token\n",
        "\n",
        "# Clone the repository using the token\n",
        "# Replace 'Vinay-O/HouseBrainLLM' with your own GitHub username and repository if it's different.\n",
        "!git clone https://{os.environ.get('GITHUB_TOKEN')}@github.com/Vinay-O/HouseBrainLLM.git\n",
        "%cd HouseBrainLLM\n",
        "\n",
        "print(\"\\\\nâœ… Repository cloned successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Install and Start Ollama Server\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install and start Ollama in the background\n",
        "!echo \"Installing Ollama...\"\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "\n",
        "import subprocess\n",
        "\n",
        "# Run Ollama serve in the background\n",
        "command = \"ollama serve\"\n",
        "process = subprocess.Popen(command.split(), stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "print(\"Ollama server starting in the background...\")\n",
        "\n",
        "!sleep 5 # Give the server a moment to start up properly.\n",
        "print(\"âœ… Ollama server should be running.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Health Check: Verify Ollama Server is Running\n",
        "# This command lists the models Ollama is serving. \n",
        "# It should return an empty list now, but confirm the server is responsive.\n",
        "print(\"--- Ollama Health Check ---\")\n",
        "!ollama list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Provision LLM Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pull the fast model for generation (Llama 3 8B)\n",
        "!echo \"Pulling Llama 3 8B model (for generation)...\"\n",
        "!ollama pull llama3:8b\n",
        "print(\"\\\\n--- Verification ---\")\n",
        "!ollama list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pull the powerful model for repair (Qwen3 30B)\n",
        "# This will download ~19GB.\n",
        "!echo \"Pulling Qwen3 30B model (for repair)...\"\n",
        "!ollama pull qwen3:30b\n",
        "print(\"\\\\n--- Verification ---\")\n",
        "!ollama list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Create Prompt List\n",
        "\n",
        "Here, we create the `prompts.txt` file that the data factory will use as its workload. You can expand the `prompts` list below with as many scenarios as you need.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# You can replace this list with the contents of 'formatted_prompts.txt'\n",
        "# or create a much larger list to generate more data.\n",
        "prompts = [\n",
        "    \"Design a modern, single-story 3BHK house for a 50x80 feet plot. It must feature an open-plan kitchen and living area, a dedicated home office, and be Vastu-compliant with a North-facing entrance.\",\n",
        "    \"A luxurious two-story 5BHK villa for a 100x100 feet plot, west-facing, with a swimming pool, home theater, and a large garden.\",\n",
        "    \"A compact, budget-friendly 2BHK apartment design for a family of four, with a total area of 1200 sqft.\",\n",
        "    \"A traditional Kerala-style 'Nalukettu' house with a central courtyard for a 60x90 feet south-facing plot.\",\n",
        "    \"Design a G+2 building on a 30x60 feet plot. The ground floor should be for parking. The first and second floors should be identical 2BHK units.\",\n",
        "    \"Create a Vastu-compliant 4BHK duplex house plan for an east-facing 40x60 feet plot, including a pooja room and a small garden.\",\n",
        "    \"A minimalist 1BHK studio apartment layout for a young professional, maximizing space in a 600 sqft area.\",\n",
        "    \"Design a sprawling farmhouse on a 1-acre plot with 4 bedrooms, a large verandah, servant's quarters, and space for organic farming.\",\n",
        "    \"A G+1 6BHK joint family home for a 50x100 feet plot, with separate kitchen and living areas on each floor but connected by an internal staircase.\",\n",
        "    \"A contemporary 3BHK house with a budget of 50 lakhs for a 30x50 feet plot, prioritizing natural light and ventilation.\",\n",
        "]\n",
        "\n",
        "with open('prompts.txt', 'w') as f:\n",
        "    for prompt in prompts:\n",
        "        f.write(prompt + '\\\\n')\n",
        "\n",
        "print(f\"âœ… Created prompts.txt with {len(prompts)} prompts.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Run the Automated Curation Factory\n",
        "\n",
        "This final step will loop through your `prompts.txt` file and run the full pipeline for each one. Validated files will be saved to your Google Drive.\n",
        "\n",
        "**This process can run for a very long time.** Ensure your Colab session does not time out. For very large datasets, you may need to use Colab Pro or run this script on a dedicated machine.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "prompts_file = 'prompts.txt'\n",
        "# This path points to a folder in your Google Drive where the final data will be saved.\n",
        "output_directory = '/content/drive/MyDrive/housebrain_automated_dataset'\n",
        "\n",
        "# Ensure the output directory exists\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "print(f\"Output directory is ready at: {output_directory}\")\n",
        "\n",
        "with open(prompts_file, 'r') as f:\n",
        "    prompts = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "print(f\"Found {len(prompts)} prompts to process.\")\n",
        "\n",
        "for i, prompt in enumerate(prompts):\n",
        "    print(f\"\"\"\n",
        "    =================================================\n",
        "    Processing prompt {i+1}/{len(prompts)}\n",
        "    PROMPT: {prompt[:100]}...\n",
        "    =================================================\n",
        "    \"\"\")\n",
        "    \n",
        "    command = [\n",
        "        'python',\n",
        "        'scripts/automated_curation.py',\n",
        "        '--prompt', prompt,\n",
        "        '--output-dir', output_directory,\n",
        "        '--model', 'llama3:8b',\n",
        "        '--repair-model', 'qwen3:30b',\n",
        "        '--max-retries', '3'\n",
        "    ]\n",
        "    \n",
        "    # Using Popen to stream the output in real-time in the Colab console\n",
        "    with subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1, universal_newlines=True) as p:\n",
        "        if p.stdout:\n",
        "            for line in p.stdout:\n",
        "                print(line, end='', flush=True)\n",
        "\n",
        "print(\"\\\\n\\\\nðŸŽ‰ Data Factory run complete! Check your Google Drive for the generated files.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install necessary Python packages\n",
        "# requests is used by our scripts to communicate with the Ollama server.\n",
        "!pip install -q requests\n",
        "print(\"âœ… Dependencies installed.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
