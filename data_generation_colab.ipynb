{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HouseBrain Data Factory 2.0: The Architect's Assembly Line\n",
    "\n",
    "This notebook is the control center for generating a high-quality, architecturally-sound dataset for training the HouseBrain LLM. It leverages the \"Architect's Assembly Line\" script, which is a robust, multi-stage pipeline designed to guide an LLM in creating valid house plans.\n",
    "\n",
    "**Our Strategy:**\n",
    "1.  **Use a powerful \"Generator\" model** (e.g., `qwen2:7b`, as recommended) within the pipeline to create draft plans.\n",
    "2.  **Run the pipeline at scale** on a large list of diverse architectural prompts.\n",
    "3.  **Save the validated, \"Gold Standard\" outputs** directly to your Google Drive.\n",
    "4.  Use this curated dataset in a separate notebook to fine-tune a more specialized \"Architect\" model (e.g., `Llama 3`).\n",
    "\n",
    "## Instructions\n",
    "1.  **Set Your GitHub PAT**: In the \"Setup\" section, you will be prompted to enter a GitHub Personal Access Token. This is required to clone the private `HouseBrainLLM` repository.\n",
    "2.  **Define Your Prompts**: In the \"Run Data Factory\" section, a default list of prompts is provided. You should replace or extend this with a much larger and more diverse list for a full data generation run.\n",
    "3.  **Run All Cells**: Once configured, select \"Runtime\" -> \"Run all\" from the menu. The notebook will set up the environment, download the necessary models, and begin the data generation process, saving the results to your Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1",
    "outputId": "35851493-2771-464a-e45f-c088a8738363",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title ## 1. Setup Environment\n",
    "# @markdown Mount Google Drive and clone the repository using a secure token.\n",
    "from google.colab import drive\n",
    "import os\n",
    "import getpass\n",
    "import subprocess\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"‚úÖ Google Drive mounted.\")\n",
    "\n",
    "# --- GitHub Setup ---\n",
    "#@markdown Enter your GitHub Personal Access Token (PAT) with repo access.\n",
    "GITHUB_TOKEN = getpass.getpass('Enter your GitHub PAT: ')\n",
    "REPO_URL = f\"https://{GITHUB_TOKEN}@github.com/Vinay-O/HouseBrainLLM.git\"\n",
    "REPO_DIR = \"/content/HouseBrainLLM\"\n",
    "\n",
    "# Clone the repository\n",
    "if os.path.exists(REPO_DIR):\n",
    "    print(\"Repository already exists. Pulling latest changes...\")\n",
    "    subprocess.run(f\"cd {REPO_DIR} && git pull\", shell=True, check=True)\n",
    "else:\n",
    "    print(\"Cloning repository...\")\n",
    "    subprocess.run(f\"git clone {REPO_URL} {REPO_DIR}\", shell=True, check=True)\n",
    "\n",
    "print(\"‚úÖ Repository is ready.\")\n",
    "\n",
    "# --- Install Dependencies ---\n",
    "#@markdown Install necessary Python packages.\n",
    "!pip install -q pydantic GitPython\n",
    "\n",
    "print(\"‚úÖ Dependencies installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title ## 2. Configure and Start Ollama Server\n",
    "# @markdown This cell will download and start the Ollama server, then pull the specified model.\n",
    "# @markdown The process will take a few minutes.\n",
    "\n",
    "MODEL_NAME = \"mixtral:instruct\" # @param [\"mixtral:instruct\", \"qwen2:7b\", \"llama3:8b\", \"mistral:7b-instruct\", \"qwen2:72b\"]\n",
    "\n",
    "# Download and start Ollama\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "import threading\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "def run_ollama():\n",
    "    try:\n",
    "        subprocess.run(\"ollama serve\", shell=True, check=True, capture_output=True, text=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Ollama server failed: {e.stderr}\")\n",
    "\n",
    "print(\"üöÄ Starting Ollama server in the background...\")\n",
    "ollama_thread = threading.Thread(target=run_ollama)\n",
    "ollama_thread.daemon = True\n",
    "ollama_thread.start()\n",
    "\n",
    "# Wait for the server to be ready\n",
    "print(\"‚è≥ Waiting for Ollama server to initialize...\")\n",
    "time.sleep(10)\n",
    "\n",
    "# Pull the model\n",
    "print(f\"üì¶ Pulling model: {MODEL_NAME}. This may take a while...\")\n",
    "try:\n",
    "    subprocess.run(f\"ollama pull {MODEL_NAME}\", shell=True, check=True, capture_output=True, text=True)\n",
    "    print(f\"‚úÖ Model {MODEL_NAME} is ready.\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Failed to pull model. Trying default tag...\")\n",
    "    base_model = MODEL_NAME.split(':')[0]\n",
    "    subprocess.run(f\"ollama pull {base_model}\", shell=True, check=True)\n",
    "    print(f\"‚úÖ Model {base_model} is ready.\")\n",
    "\n",
    "# Verify Ollama is running\n",
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title ## 3. Run the Data Factory\n",
    "# @markdown Execute the Architect's Assembly Line for each prompt.\n",
    "# @markdown You should replace the `prompts` list with your own extensive list for a full run.\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import textwrap\n",
    "\n",
    "# --- Configuration ---\n",
    "#@markdown Define the list of prompts to be processed.\n",
    "prompts = [\n",
    "    \"A modern, single-story 3BHK house for a 50x80 feet plot. It must feature an open-plan kitchen and living area, a dedicated home office, and be Vastu-compliant with a North-facing entrance.\",\n",
    "    \"A luxurious two-story 5BHK villa for a 100x100 feet plot, west-facing, with a swimming pool, home theater, and a large garden.\",\n",
    "    \"A compact, budget-friendly 2BHK apartment design for a family of four, with a total area of 1200 sqft.\",\n",
    "    \"A traditional Kerala-style 'Nalukettu' house with a central courtyard for a 60x90 feet south-facing plot.\",\n",
    "    \"Design a G+2 building on a 30x60 feet plot. The ground floor should be for parking. The first and second floors should be identical 2BHK units.\",\n",
    "]\n",
    "\n",
    "#@markdown Specify the output directory in your Google Drive.\n",
    "DRIVE_OUTPUT_DIR = \"/content/drive/MyDrive/housebrain_dataset\"\n",
    "\n",
    "# --- Execution ---\n",
    "os.chdir(REPO_DIR)\n",
    "script_path = \"scripts/run_complete_assembly_line.py\"\n",
    "run_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = os.path.join(DRIVE_OUTPUT_DIR, f\"run_{run_timestamp}\")\n",
    "\n",
    "print(f\"Output directory is ready at: {output_dir}\")\n",
    "print(f\"Found {len(prompts)} prompts to process.\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for i, prompt in enumerate(prompts):\n",
    "    print(f\"Processing prompt {i+1}/{len(prompts)}\")\n",
    "    prompt_short = textwrap.shorten(prompt, width=100, placeholder=\"...\")\n",
    "    print(f\"PROMPT: {prompt_short}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Create a unique name for the run based on the prompt\n",
    "    run_name = f\"prompt_{i+1:04d}\"\n",
    "\n",
    "    command = [\n",
    "        \"python3\",\n",
    "        script_path,\n",
    "        \"--prompt\", prompt,\n",
    "        \"--output-dir\", output_dir,\n",
    "        \"--run-name\", run_name,\n",
    "        \"--model\", MODEL_NAME,\n",
    "        \"--max-retries\", \"5\" # Be more resilient in Colab\n",
    "    ]\n",
    "\n",
    "    subprocess.run(command)\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "print(\"üéâ Data Factory run complete! Check your Google Drive for the generated files.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "colab-‡¶§‡¶á",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
